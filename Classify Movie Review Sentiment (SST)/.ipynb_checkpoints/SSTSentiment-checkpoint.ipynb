{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AAd39iApMJA"
   },
   "source": [
    "# Task: Classify a movie review based on sentiment\n",
    "\n",
    "04/17/2023\n",
    "\n",
    "[Link to GitHub repo](https://github.com/lprockop/TextClassification-StanfordSST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzQyHyQX3XYR"
   },
   "source": [
    "## Import modules, import data, instantiate competition, create preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOTDnzN53zYz"
   },
   "source": [
    "### Import modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xh1G2LM2qri9"
   },
   "outputs": [],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare==0.0.189\n",
    "#RESTART RUNTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzKoEMslmkZg",
    "outputId": "4fc099e9-fc64-4713-e857-041ff1c3132b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [=============================================>   ]\n",
      "\n",
      "Data downloaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    The Rock is destined to be the 21st Century 's...\n",
       "1    The gorgeously elaborate continuation of `` Th...\n",
       "2    Singer/composer Bryan Adams contributes a slew...\n",
       "3                 Yet the act is still charming here .\n",
       "4    Whether or not you 're enlightened by any of D...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "\n",
    "# Get competition data\n",
    "from aimodelshare import download_data\n",
    "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') \n",
    "\n",
    "# Set up X_train, X_test, and y_train_labels objects\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
    "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
    "\n",
    "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
    "\n",
    "# ohe encode Y data\n",
    "y_train = pd.get_dummies(y_train_labels)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0DSIq9y3cBq",
    "outputId": "941b26d6-b286-4b23-8dae-b610f6060453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set credentials using modelshare.org username/password\n",
    "from aimodelshare.aws import set_credentials\n",
    "import aimodelshare as ai\n",
    "\n",
    "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "set_credentials(apiurl=apiurl)\n",
    "\n",
    "#Instantiate Competition\n",
    "mycompetition= ai.Competition(apiurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNw-INmM3dp7"
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-KWRWVApuFj",
    "outputId": "20c91b46-f16d-4f49-d745-c0c195601285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 40)\n",
      "(1821, 40)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "\n",
    "# This preprocessor function makes use of the tf.keras tokenizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Build vocabulary from training text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# preprocessor tokenizes words and makes sure all documents have the same length\n",
    "def preprocessor(data, maxlen=40, max_words=10000):\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "    return X\n",
    "\n",
    "print(preprocessor(X_train).shape)\n",
    "print(preprocessor(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xi-4pyAitEBq",
    "outputId": "b83f83c3-d424-422b-b5ac-f3f2cfda702d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your preprocessor is now saved to 'preprocessor.zip'\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.export_preprocessor(preprocessor,\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wJGIIBtqd7i"
   },
   "source": [
    "## Question 1: Discuss dataset in general terms and the purpose of building this model. Who could benefit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHf2TU_LqjsL"
   },
   "source": [
    "The feature in this dataset is text (movie reviews) and the target is a negative or positive sentiment classification. Predicting sentiment has a variety of applications, including generating overall impression scores (for example, a movie's composite rating could be gleaned from the percentage of reviews that are positive or negative) or identifying potential customer support issues for a company by identifying negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtezEXOzqkdZ",
    "outputId": "a291bb0a-8bc8-4825-ac0c-75fe8de8afc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Rock is destined to be the 21st Century 's...\n",
       "1    The gorgeously elaborate continuation of `` Th...\n",
       "2    Singer/composer Bryan Adams contributes a slew...\n",
       "3                 Yet the act is still charming here .\n",
       "4    Whether or not you 're enlightened by any of D...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Pp96q8Byr3Z-",
    "outputId": "6ca35d40-fce6-43e8-8a4e-2c62ae3f8b57"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-03f35003-ed34-4851-b765-a360366186c9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03f35003-ed34-4851-b765-a360366186c9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-03f35003-ed34-4851-b765-a360366186c9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-03f35003-ed34-4851-b765-a360366186c9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Negative  Positive\n",
       "0         0         1\n",
       "1         0         1\n",
       "2         0         1\n",
       "3         0         1\n",
       "4         0         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykPcSoNtpwUT"
   },
   "source": [
    "## Question 2: build 3 prediction models to predict SST sentiment well & Question 4: Submit to competiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cxxBBOTp1rz"
   },
   "source": [
    "### 2.1: Embedding layer and LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgS_yru5qBeK",
    "outputId": "9d223aa8-1725-49c2-a267-ecf22570715a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 13s 57ms/step - loss: 0.6509 - acc: 0.6208 - val_loss: 0.7412 - val_acc: 0.4949\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.4945 - acc: 0.7690 - val_loss: 0.7274 - val_acc: 0.6879\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 5s 30ms/step - loss: 0.3799 - acc: 0.8315 - val_loss: 0.6147 - val_acc: 0.7262\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.3074 - acc: 0.8727 - val_loss: 0.6242 - val_acc: 0.7139\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.2643 - acc: 0.8900 - val_loss: 0.7489 - val_acc: 0.6799\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 5s 30ms/step - loss: 0.2211 - acc: 0.9093 - val_loss: 0.6473 - val_acc: 0.7197\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.2000 - acc: 0.9212 - val_loss: 0.5435 - val_acc: 0.7861\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 7s 38ms/step - loss: 0.1741 - acc: 0.9305 - val_loss: 0.7418 - val_acc: 0.7211\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 5s 30ms/step - loss: 0.1568 - acc: 0.9400 - val_loss: 0.6480 - val_acc: 0.7428\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.1446 - acc: 0.9435 - val_loss: 0.6442 - val_acc: 0.7384\n"
     ]
    }
   ],
   "source": [
    "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 16, input_length=40))\n",
    "model2.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model2.add(LSTM(32, dropout=0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model2.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cic4WqMNrXnn"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model2, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model2.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKZHMI063sfi",
    "outputId": "c3570c8a-f2da-4d13-e268-bd286963dcd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 22ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 252\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#submit model\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0P482AwFp4Pb"
   },
   "source": [
    "### 2.2: Embedding layer and Conv1d layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipPeumkCp5vY",
    "outputId": "bf9c755b-aae9-48d1-a9b4-f7375e37952f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 37, 16)            1040      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 16)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 16)             1040      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 16)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,170\n",
      "Trainable params: 162,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 2s 5ms/step - loss: 0.6687 - acc: 0.6149 - val_loss: 0.8896 - val_acc: 0.1488\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.6642 - acc: 0.6149 - val_loss: 0.8663 - val_acc: 0.1488\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.6412 - acc: 0.6149 - val_loss: 0.8539 - val_acc: 0.1488\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.5770 - acc: 0.6472 - val_loss: 0.8445 - val_acc: 0.3815\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.4931 - acc: 0.8497 - val_loss: 0.7853 - val_acc: 0.5592\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.4068 - acc: 0.8913 - val_loss: 0.8494 - val_acc: 0.5542\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.3314 - acc: 0.9133 - val_loss: 0.7939 - val_acc: 0.5795\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2726 - acc: 0.9272 - val_loss: 0.9413 - val_acc: 0.5347\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 1s 4ms/step - loss: 0.2270 - acc: 0.9341 - val_loss: 0.8936 - val_acc: 0.5759\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.1923 - acc: 0.9447 - val_loss: 0.7929 - val_acc: 0.6134\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(10000, 16, input_length=40))\n",
    "model3.add(layers.Conv1D(16, 4, activation='relu')) \n",
    "model3.add(layers.MaxPooling1D(8))\n",
    "model3.add(layers.Conv1D(16, 4, activation='relu'))\n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(4))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model3.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWtDduMyuqyy"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model3, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model3.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADgTwjlb3t8-",
    "outputId": "f96d66d9-e7bd-43c3-eb85-26d042807bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 253\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Submit model\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model3.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model3.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or4DVouUp8z0"
   },
   "source": [
    "### 2.3: Transfer learning with glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9tooawkp-L8",
    "outputId": "5741024d-2508-4564-8d49-57419736ac67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-17 01:22:21--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 01:22:21--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 01:22:21--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182753 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 3m 6s   \n",
      "\n",
      "2023-04-17 01:25:27 (4.42 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
    "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
    "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZetNv3cysLw",
    "outputId": "65207bc1-3083-4093-db7c-62f7190373a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n",
      "  inflating: glove.6B.50d.txt        \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_dZ00-XyrBk",
    "outputId": "ca505eeb-a9e7-4abd-c6e3-dee4a27ceb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding data for 100 feature embedding matrix\n",
    "import os\n",
    "glove_dir = os.getcwd()\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# Tokenize the data into one hot vectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100  # We will cut reviews after 100 words in sequence\n",
    "training_samples = 10000  # We will be training on 10000 samples\n",
    "validation_samples = 10000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AM8txI5YyoS3",
    "outputId": "c66b7664-21e2-4ac5-8db8-092003239349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13835 unique tokens.\n",
      "Shape of data tensor: (6920, 100)\n",
      "Shape of label tensor: (6920,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train) # converts words in each text to each word's numeric index in tokenizer dictionary.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(y_train['Negative'])\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5n62_y5MymKv"
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "X_train_1 = data[:training_samples] #100 words\n",
    "y_train_1 = labels[:training_samples]\n",
    "X_val_1 = data[training_samples: training_samples + validation_samples]\n",
    "y_val_1 = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn_9r-Bwykq6"
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_dim = 100 # change if you use txt files using larger number of features\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIptbrk4qFhs",
    "outputId": "c9a733fa-a089-4c1a-e30a-7457edb29214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                320032    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "217/217 [==============================] - 2s 5ms/step - loss: 0.6338 - acc: 0.6413\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 1s 5ms/step - loss: 0.5064 - acc: 0.7503\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 0.4282 - acc: 0.8051\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.3541 - acc: 0.8499\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.2816 - acc: 0.8855\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 2s 7ms/step - loss: 0.2180 - acc: 0.9142\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 2s 8ms/step - loss: 0.1646 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 1s 7ms/step - loss: 0.1207 - acc: 0.9637\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 1s 5ms/step - loss: 0.0876 - acc: 0.9763\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 1s 5ms/step - loss: 0.0621 - acc: 0.9851\n"
     ]
    }
   ],
   "source": [
    "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
    "from tensorflow.keras.layers import Dense, Embedding,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model4 = tf.keras.Sequential()\n",
    "model4.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model4.add(tf.keras.layers.Flatten())\n",
    "model4.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model4.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model4.summary()\n",
    "\n",
    "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
    "model4.layers[0].set_weights([embedding_matrix])\n",
    "model4.layers[0].trainable = False\n",
    "\n",
    "model4.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model4.fit(X_train_1, y_train_1,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val_1, y_val_1))\n",
    "model4.save_weights('pre_trained_glove_model.h5')\n",
    "\n",
    "# Training data small to speed up training. Increase for better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BHXulp0uAcQ"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model4, framework='keras',\n",
    "                          transfer_learning=True,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model4.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQFqnbd_17U6",
    "outputId": "b1fd1aa9-74d6-4c04-fdd1-a175d9cef1c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 255\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# submit model\n",
    "\n",
    "#using tokenizer object we fit to test data above\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_1 = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model4.predict(X_test_1).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model4.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyknzP3jqF3_"
   },
   "source": [
    "## Question 3: Which models performed better? Relevant hyper params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Icutp-W3AeC"
   },
   "source": [
    "My best model was a Sequential model with a depth of 5, including 1 embedding layer, 2 LSTM layers, and no conv1d layers. It did not use transfer learning. The optimizer was RMSprop. The f1 score for this model was 79.06%.\n",
    "(Note: code below to get leaderboard was re-run after submitting later models; model number 55 (index 48) was the best-performing from the first 3 models I ran.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "NJa9VM33qJm9",
    "outputId": "d443b24d-30fb-40f6-d494-97c6e1fac0ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_55308_row0_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 79.4%, transparent 79.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row0_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row0_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 80.0%, transparent 80.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row0_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 79.4%, transparent 79.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row0_col4, #T_55308_row0_col5, #T_55308_row0_col6, #T_55308_row0_col7, #T_55308_row0_col8, #T_55308_row0_col9, #T_55308_row0_col10, #T_55308_row0_col11, #T_55308_row0_col12, #T_55308_row0_col13, #T_55308_row0_col14, #T_55308_row0_col15, #T_55308_row0_col16, #T_55308_row0_col17, #T_55308_row0_col18, #T_55308_row0_col19, #T_55308_row0_col20, #T_55308_row0_col21, #T_55308_row0_col22, #T_55308_row0_col23, #T_55308_row0_col24, #T_55308_row0_col25, #T_55308_row0_col26, #T_55308_row0_col27, #T_55308_row0_col28, #T_55308_row0_col29, #T_55308_row0_col30, #T_55308_row0_col31, #T_55308_row0_col32, #T_55308_row0_col33, #T_55308_row1_col4, #T_55308_row1_col5, #T_55308_row1_col6, #T_55308_row1_col7, #T_55308_row1_col8, #T_55308_row1_col9, #T_55308_row1_col10, #T_55308_row1_col11, #T_55308_row1_col12, #T_55308_row1_col13, #T_55308_row1_col14, #T_55308_row1_col15, #T_55308_row1_col16, #T_55308_row1_col17, #T_55308_row1_col18, #T_55308_row1_col19, #T_55308_row1_col20, #T_55308_row1_col21, #T_55308_row1_col22, #T_55308_row1_col23, #T_55308_row1_col24, #T_55308_row1_col25, #T_55308_row1_col26, #T_55308_row1_col27, #T_55308_row1_col28, #T_55308_row1_col29, #T_55308_row1_col30, #T_55308_row1_col31, #T_55308_row1_col32, #T_55308_row1_col33, #T_55308_row2_col4, #T_55308_row2_col5, #T_55308_row2_col6, #T_55308_row2_col7, #T_55308_row2_col8, #T_55308_row2_col9, #T_55308_row2_col10, #T_55308_row2_col11, #T_55308_row2_col12, #T_55308_row2_col13, #T_55308_row2_col14, #T_55308_row2_col15, #T_55308_row2_col16, #T_55308_row2_col17, #T_55308_row2_col18, #T_55308_row2_col19, #T_55308_row2_col20, #T_55308_row2_col21, #T_55308_row2_col22, #T_55308_row2_col23, #T_55308_row2_col24, #T_55308_row2_col25, #T_55308_row2_col26, #T_55308_row2_col27, #T_55308_row2_col28, #T_55308_row2_col29, #T_55308_row2_col30, #T_55308_row2_col31, #T_55308_row2_col32, #T_55308_row2_col33, #T_55308_row3_col4, #T_55308_row3_col5, #T_55308_row3_col6, #T_55308_row3_col7, #T_55308_row3_col8, #T_55308_row3_col9, #T_55308_row3_col10, #T_55308_row3_col11, #T_55308_row3_col12, #T_55308_row3_col13, #T_55308_row3_col14, #T_55308_row3_col15, #T_55308_row3_col16, #T_55308_row3_col17, #T_55308_row3_col18, #T_55308_row3_col19, #T_55308_row3_col20, #T_55308_row3_col21, #T_55308_row3_col22, #T_55308_row3_col23, #T_55308_row3_col24, #T_55308_row3_col25, #T_55308_row3_col26, #T_55308_row3_col27, #T_55308_row3_col28, #T_55308_row3_col29, #T_55308_row3_col30, #T_55308_row3_col31, #T_55308_row3_col32, #T_55308_row3_col33, #T_55308_row4_col4, #T_55308_row4_col5, #T_55308_row4_col6, #T_55308_row4_col7, #T_55308_row4_col8, #T_55308_row4_col9, #T_55308_row4_col10, #T_55308_row4_col11, #T_55308_row4_col12, #T_55308_row4_col13, #T_55308_row4_col14, #T_55308_row4_col15, #T_55308_row4_col16, #T_55308_row4_col17, #T_55308_row4_col18, #T_55308_row4_col19, #T_55308_row4_col20, #T_55308_row4_col21, #T_55308_row4_col22, #T_55308_row4_col23, #T_55308_row4_col24, #T_55308_row4_col25, #T_55308_row4_col26, #T_55308_row4_col27, #T_55308_row4_col28, #T_55308_row4_col29, #T_55308_row4_col30, #T_55308_row4_col31, #T_55308_row4_col32, #T_55308_row4_col33, #T_55308_row5_col4, #T_55308_row5_col5, #T_55308_row5_col6, #T_55308_row5_col7, #T_55308_row5_col8, #T_55308_row5_col9, #T_55308_row5_col10, #T_55308_row5_col11, #T_55308_row5_col12, #T_55308_row5_col13, #T_55308_row5_col14, #T_55308_row5_col15, #T_55308_row5_col16, #T_55308_row5_col17, #T_55308_row5_col18, #T_55308_row5_col19, #T_55308_row5_col20, #T_55308_row5_col21, #T_55308_row5_col22, #T_55308_row5_col23, #T_55308_row5_col24, #T_55308_row5_col25, #T_55308_row5_col26, #T_55308_row5_col27, #T_55308_row5_col28, #T_55308_row5_col29, #T_55308_row5_col30, #T_55308_row5_col31, #T_55308_row5_col32, #T_55308_row5_col33, #T_55308_row6_col4, #T_55308_row6_col5, #T_55308_row6_col6, #T_55308_row6_col7, #T_55308_row6_col8, #T_55308_row6_col9, #T_55308_row6_col10, #T_55308_row6_col11, #T_55308_row6_col12, #T_55308_row6_col13, #T_55308_row6_col14, #T_55308_row6_col15, #T_55308_row6_col16, #T_55308_row6_col17, #T_55308_row6_col18, #T_55308_row6_col19, #T_55308_row6_col20, #T_55308_row6_col21, #T_55308_row6_col22, #T_55308_row6_col23, #T_55308_row6_col24, #T_55308_row6_col25, #T_55308_row6_col26, #T_55308_row6_col27, #T_55308_row6_col28, #T_55308_row6_col29, #T_55308_row6_col30, #T_55308_row6_col31, #T_55308_row6_col32, #T_55308_row6_col33, #T_55308_row7_col4, #T_55308_row7_col5, #T_55308_row7_col6, #T_55308_row7_col7, #T_55308_row7_col8, #T_55308_row7_col9, #T_55308_row7_col10, #T_55308_row7_col11, #T_55308_row7_col12, #T_55308_row7_col13, #T_55308_row7_col14, #T_55308_row7_col15, #T_55308_row7_col16, #T_55308_row7_col17, #T_55308_row7_col18, #T_55308_row7_col19, #T_55308_row7_col20, #T_55308_row7_col21, #T_55308_row7_col22, #T_55308_row7_col23, #T_55308_row7_col24, #T_55308_row7_col25, #T_55308_row7_col26, #T_55308_row7_col27, #T_55308_row7_col28, #T_55308_row7_col29, #T_55308_row7_col30, #T_55308_row7_col31, #T_55308_row7_col32, #T_55308_row7_col33, #T_55308_row8_col4, #T_55308_row8_col5, #T_55308_row8_col6, #T_55308_row8_col7, #T_55308_row8_col8, #T_55308_row8_col9, #T_55308_row8_col10, #T_55308_row8_col11, #T_55308_row8_col12, #T_55308_row8_col13, #T_55308_row8_col14, #T_55308_row8_col15, #T_55308_row8_col16, #T_55308_row8_col17, #T_55308_row8_col18, #T_55308_row8_col19, #T_55308_row8_col20, #T_55308_row8_col21, #T_55308_row8_col22, #T_55308_row8_col23, #T_55308_row8_col24, #T_55308_row8_col25, #T_55308_row8_col26, #T_55308_row8_col27, #T_55308_row8_col28, #T_55308_row8_col29, #T_55308_row8_col30, #T_55308_row8_col31, #T_55308_row8_col32, #T_55308_row8_col33, #T_55308_row9_col4, #T_55308_row9_col5, #T_55308_row9_col6, #T_55308_row9_col7, #T_55308_row9_col8, #T_55308_row9_col9, #T_55308_row9_col10, #T_55308_row9_col11, #T_55308_row9_col12, #T_55308_row9_col13, #T_55308_row9_col14, #T_55308_row9_col15, #T_55308_row9_col16, #T_55308_row9_col17, #T_55308_row9_col18, #T_55308_row9_col19, #T_55308_row9_col20, #T_55308_row9_col21, #T_55308_row9_col22, #T_55308_row9_col23, #T_55308_row9_col24, #T_55308_row9_col25, #T_55308_row9_col26, #T_55308_row9_col27, #T_55308_row9_col28, #T_55308_row9_col29, #T_55308_row9_col30, #T_55308_row9_col31, #T_55308_row9_col32, #T_55308_row9_col33, #T_55308_row10_col4, #T_55308_row10_col5, #T_55308_row10_col6, #T_55308_row10_col7, #T_55308_row10_col8, #T_55308_row10_col9, #T_55308_row10_col10, #T_55308_row10_col11, #T_55308_row10_col12, #T_55308_row10_col13, #T_55308_row10_col14, #T_55308_row10_col15, #T_55308_row10_col16, #T_55308_row10_col17, #T_55308_row10_col18, #T_55308_row10_col19, #T_55308_row10_col20, #T_55308_row10_col21, #T_55308_row10_col22, #T_55308_row10_col23, #T_55308_row10_col24, #T_55308_row10_col25, #T_55308_row10_col26, #T_55308_row10_col27, #T_55308_row10_col28, #T_55308_row10_col29, #T_55308_row10_col30, #T_55308_row10_col31, #T_55308_row10_col32, #T_55308_row10_col33 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_55308_row1_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row1_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 79.1%, transparent 79.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row1_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 80.4%, transparent 80.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row1_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row2_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 77.5%, transparent 77.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row2_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 77.4%, transparent 77.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row2_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 78.0%, transparent 78.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row2_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 77.5%, transparent 77.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row3_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 76.4%, transparent 76.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row3_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 76.2%, transparent 76.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row3_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 77.2%, transparent 77.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row3_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 76.4%, transparent 76.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row4_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row4_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 70.0%, transparent 70.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row4_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 71.8%, transparent 71.8%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row4_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row5_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 69.9%, transparent 69.9%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row5_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 69.7%, transparent 69.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row5_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row5_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 69.9%, transparent 69.9%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row6_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 68.7%, transparent 68.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row6_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 68.2%, transparent 68.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row6_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.0%, transparent 70.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row6_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 68.7%, transparent 68.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row7_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 65.4%, transparent 65.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row7_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 63.1%, transparent 63.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row7_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.6%, transparent 70.6%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row7_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 65.5%, transparent 65.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row8_col0, #T_55308_row9_col0, #T_55308_row10_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 50.1%, transparent 50.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row8_col1, #T_55308_row9_col1, #T_55308_row10_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 33.4%, transparent 33.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row8_col2, #T_55308_row9_col2, #T_55308_row10_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 25.0%, transparent 25.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_55308_row8_col3, #T_55308_row9_col3, #T_55308_row10_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 50.0%, transparent 50.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_55308\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_55308_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_55308_level0_col1\" class=\"col_heading level0 col1\" >f1_score</th>\n",
       "      <th id=\"T_55308_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_55308_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_55308_level0_col4\" class=\"col_heading level0 col4\" >ml_framework</th>\n",
       "      <th id=\"T_55308_level0_col5\" class=\"col_heading level0 col5\" >transfer_learning</th>\n",
       "      <th id=\"T_55308_level0_col6\" class=\"col_heading level0 col6\" >deep_learning</th>\n",
       "      <th id=\"T_55308_level0_col7\" class=\"col_heading level0 col7\" >model_type</th>\n",
       "      <th id=\"T_55308_level0_col8\" class=\"col_heading level0 col8\" >depth</th>\n",
       "      <th id=\"T_55308_level0_col9\" class=\"col_heading level0 col9\" >num_params</th>\n",
       "      <th id=\"T_55308_level0_col10\" class=\"col_heading level0 col10\" >embedding_layers</th>\n",
       "      <th id=\"T_55308_level0_col11\" class=\"col_heading level0 col11\" >conv1d_layers</th>\n",
       "      <th id=\"T_55308_level0_col12\" class=\"col_heading level0 col12\" >maxpooling1d_layers</th>\n",
       "      <th id=\"T_55308_level0_col13\" class=\"col_heading level0 col13\" >simplernn_layers</th>\n",
       "      <th id=\"T_55308_level0_col14\" class=\"col_heading level0 col14\" >dropout_layers</th>\n",
       "      <th id=\"T_55308_level0_col15\" class=\"col_heading level0 col15\" >flatten_layers</th>\n",
       "      <th id=\"T_55308_level0_col16\" class=\"col_heading level0 col16\" >lstm_layers</th>\n",
       "      <th id=\"T_55308_level0_col17\" class=\"col_heading level0 col17\" >inputlayer_layers</th>\n",
       "      <th id=\"T_55308_level0_col18\" class=\"col_heading level0 col18\" >concatenate_layers</th>\n",
       "      <th id=\"T_55308_level0_col19\" class=\"col_heading level0 col19\" >bidirectional_layers</th>\n",
       "      <th id=\"T_55308_level0_col20\" class=\"col_heading level0 col20\" >globalmaxpooling1d_layers</th>\n",
       "      <th id=\"T_55308_level0_col21\" class=\"col_heading level0 col21\" >globalaveragepooling1d_layers</th>\n",
       "      <th id=\"T_55308_level0_col22\" class=\"col_heading level0 col22\" >dense_layers</th>\n",
       "      <th id=\"T_55308_level0_col23\" class=\"col_heading level0 col23\" >batchnormalization_layers</th>\n",
       "      <th id=\"T_55308_level0_col24\" class=\"col_heading level0 col24\" >sigmoid_act</th>\n",
       "      <th id=\"T_55308_level0_col25\" class=\"col_heading level0 col25\" >softmax_act</th>\n",
       "      <th id=\"T_55308_level0_col26\" class=\"col_heading level0 col26\" >tanh_act</th>\n",
       "      <th id=\"T_55308_level0_col27\" class=\"col_heading level0 col27\" >relu_act</th>\n",
       "      <th id=\"T_55308_level0_col28\" class=\"col_heading level0 col28\" >loss</th>\n",
       "      <th id=\"T_55308_level0_col29\" class=\"col_heading level0 col29\" >optimizer</th>\n",
       "      <th id=\"T_55308_level0_col30\" class=\"col_heading level0 col30\" >memory_size</th>\n",
       "      <th id=\"T_55308_level0_col31\" class=\"col_heading level0 col31\" >team</th>\n",
       "      <th id=\"T_55308_level0_col32\" class=\"col_heading level0 col32\" >username</th>\n",
       "      <th id=\"T_55308_level0_col33\" class=\"col_heading level0 col33\" >version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row0\" class=\"row_heading level0 row0\" >46</th>\n",
       "      <td id=\"T_55308_row0_col0\" class=\"data row0 col0\" >79.36%</td>\n",
       "      <td id=\"T_55308_row0_col1\" class=\"data row0 col1\" >79.25%</td>\n",
       "      <td id=\"T_55308_row0_col2\" class=\"data row0 col2\" >80.03%</td>\n",
       "      <td id=\"T_55308_row0_col3\" class=\"data row0 col3\" >79.37%</td>\n",
       "      <td id=\"T_55308_row0_col4\" class=\"data row0 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col6\" class=\"data row0 col6\" >True</td>\n",
       "      <td id=\"T_55308_row0_col7\" class=\"data row0 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row0_col8\" class=\"data row0 col8\" >5.000000</td>\n",
       "      <td id=\"T_55308_row0_col9\" class=\"data row0 col9\" >174658.000000</td>\n",
       "      <td id=\"T_55308_row0_col10\" class=\"data row0 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col15\" class=\"data row0 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row0_col16\" class=\"data row0 col16\" >2.000000</td>\n",
       "      <td id=\"T_55308_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col18\" class=\"data row0 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col20\" class=\"data row0 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col21\" class=\"data row0 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col22\" class=\"data row0 col22\" >1.000000</td>\n",
       "      <td id=\"T_55308_row0_col23\" class=\"data row0 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col24\" class=\"data row0 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col25\" class=\"data row0 col25\" >1.000000</td>\n",
       "      <td id=\"T_55308_row0_col26\" class=\"data row0 col26\" >2.000000</td>\n",
       "      <td id=\"T_55308_row0_col27\" class=\"data row0 col27\" >nan</td>\n",
       "      <td id=\"T_55308_row0_col28\" class=\"data row0 col28\" >str</td>\n",
       "      <td id=\"T_55308_row0_col29\" class=\"data row0 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row0_col30\" class=\"data row0 col30\" >699936.000000</td>\n",
       "      <td id=\"T_55308_row0_col31\" class=\"data row0 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row0_col32\" class=\"data row0 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row0_col33\" class=\"data row0 col33\" >252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row1\" class=\"row_heading level0 row1\" >48</th>\n",
       "      <td id=\"T_55308_row1_col0\" class=\"data row1 col0\" >79.25%</td>\n",
       "      <td id=\"T_55308_row1_col1\" class=\"data row1 col1\" >79.06%</td>\n",
       "      <td id=\"T_55308_row1_col2\" class=\"data row1 col2\" >80.41%</td>\n",
       "      <td id=\"T_55308_row1_col3\" class=\"data row1 col3\" >79.26%</td>\n",
       "      <td id=\"T_55308_row1_col4\" class=\"data row1 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col6\" class=\"data row1 col6\" >True</td>\n",
       "      <td id=\"T_55308_row1_col7\" class=\"data row1 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row1_col8\" class=\"data row1 col8\" >5.000000</td>\n",
       "      <td id=\"T_55308_row1_col9\" class=\"data row1 col9\" >174658.000000</td>\n",
       "      <td id=\"T_55308_row1_col10\" class=\"data row1 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col15\" class=\"data row1 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row1_col16\" class=\"data row1 col16\" >2.000000</td>\n",
       "      <td id=\"T_55308_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col18\" class=\"data row1 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col19\" class=\"data row1 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col20\" class=\"data row1 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col21\" class=\"data row1 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col22\" class=\"data row1 col22\" >1.000000</td>\n",
       "      <td id=\"T_55308_row1_col23\" class=\"data row1 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col24\" class=\"data row1 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col25\" class=\"data row1 col25\" >1.000000</td>\n",
       "      <td id=\"T_55308_row1_col26\" class=\"data row1 col26\" >2.000000</td>\n",
       "      <td id=\"T_55308_row1_col27\" class=\"data row1 col27\" >nan</td>\n",
       "      <td id=\"T_55308_row1_col28\" class=\"data row1 col28\" >str</td>\n",
       "      <td id=\"T_55308_row1_col29\" class=\"data row1 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row1_col30\" class=\"data row1 col30\" >699936.000000</td>\n",
       "      <td id=\"T_55308_row1_col31\" class=\"data row1 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row1_col32\" class=\"data row1 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row1_col33\" class=\"data row1 col33\" >55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row2\" class=\"row_heading level0 row2\" >99</th>\n",
       "      <td id=\"T_55308_row2_col0\" class=\"data row2 col0\" >77.50%</td>\n",
       "      <td id=\"T_55308_row2_col1\" class=\"data row2 col1\" >77.41%</td>\n",
       "      <td id=\"T_55308_row2_col2\" class=\"data row2 col2\" >77.97%</td>\n",
       "      <td id=\"T_55308_row2_col3\" class=\"data row2 col3\" >77.50%</td>\n",
       "      <td id=\"T_55308_row2_col4\" class=\"data row2 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col6\" class=\"data row2 col6\" >True</td>\n",
       "      <td id=\"T_55308_row2_col7\" class=\"data row2 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row2_col8\" class=\"data row2 col8\" >3.000000</td>\n",
       "      <td id=\"T_55308_row2_col9\" class=\"data row2 col9\" >161282.000000</td>\n",
       "      <td id=\"T_55308_row2_col10\" class=\"data row2 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col15\" class=\"data row2 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row2_col16\" class=\"data row2 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col18\" class=\"data row2 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col19\" class=\"data row2 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col20\" class=\"data row2 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col21\" class=\"data row2 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col22\" class=\"data row2 col22\" >1.000000</td>\n",
       "      <td id=\"T_55308_row2_col23\" class=\"data row2 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col24\" class=\"data row2 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col25\" class=\"data row2 col25\" >1.000000</td>\n",
       "      <td id=\"T_55308_row2_col26\" class=\"data row2 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col27\" class=\"data row2 col27\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col28\" class=\"data row2 col28\" >str</td>\n",
       "      <td id=\"T_55308_row2_col29\" class=\"data row2 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row2_col30\" class=\"data row2 col30\" >645600.000000</td>\n",
       "      <td id=\"T_55308_row2_col31\" class=\"data row2 col31\" >nan</td>\n",
       "      <td id=\"T_55308_row2_col32\" class=\"data row2 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row2_col33\" class=\"data row2 col33\" >44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row3\" class=\"row_heading level0 row3\" >117</th>\n",
       "      <td id=\"T_55308_row3_col0\" class=\"data row3 col0\" >76.40%</td>\n",
       "      <td id=\"T_55308_row3_col1\" class=\"data row3 col1\" >76.23%</td>\n",
       "      <td id=\"T_55308_row3_col2\" class=\"data row3 col2\" >77.18%</td>\n",
       "      <td id=\"T_55308_row3_col3\" class=\"data row3 col3\" >76.41%</td>\n",
       "      <td id=\"T_55308_row3_col4\" class=\"data row3 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col6\" class=\"data row3 col6\" >True</td>\n",
       "      <td id=\"T_55308_row3_col7\" class=\"data row3 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row3_col8\" class=\"data row3 col8\" >5.000000</td>\n",
       "      <td id=\"T_55308_row3_col9\" class=\"data row3 col9\" >161294.000000</td>\n",
       "      <td id=\"T_55308_row3_col10\" class=\"data row3 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col15\" class=\"data row3 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row3_col16\" class=\"data row3 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col18\" class=\"data row3 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col19\" class=\"data row3 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col20\" class=\"data row3 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col21\" class=\"data row3 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col22\" class=\"data row3 col22\" >3.000000</td>\n",
       "      <td id=\"T_55308_row3_col23\" class=\"data row3 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col24\" class=\"data row3 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col25\" class=\"data row3 col25\" >3.000000</td>\n",
       "      <td id=\"T_55308_row3_col26\" class=\"data row3 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col27\" class=\"data row3 col27\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col28\" class=\"data row3 col28\" >str</td>\n",
       "      <td id=\"T_55308_row3_col29\" class=\"data row3 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row3_col30\" class=\"data row3 col30\" >646160.000000</td>\n",
       "      <td id=\"T_55308_row3_col31\" class=\"data row3 col31\" >nan</td>\n",
       "      <td id=\"T_55308_row3_col32\" class=\"data row3 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row3_col33\" class=\"data row3 col33\" >47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row4\" class=\"row_heading level0 row4\" >160</th>\n",
       "      <td id=\"T_55308_row4_col0\" class=\"data row4 col0\" >70.47%</td>\n",
       "      <td id=\"T_55308_row4_col1\" class=\"data row4 col1\" >70.02%</td>\n",
       "      <td id=\"T_55308_row4_col2\" class=\"data row4 col2\" >71.82%</td>\n",
       "      <td id=\"T_55308_row4_col3\" class=\"data row4 col3\" >70.49%</td>\n",
       "      <td id=\"T_55308_row4_col4\" class=\"data row4 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col6\" class=\"data row4 col6\" >True</td>\n",
       "      <td id=\"T_55308_row4_col7\" class=\"data row4 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row4_col8\" class=\"data row4 col8\" >10.000000</td>\n",
       "      <td id=\"T_55308_row4_col9\" class=\"data row4 col9\" >162170.000000</td>\n",
       "      <td id=\"T_55308_row4_col10\" class=\"data row4 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row4_col11\" class=\"data row4 col11\" >2.000000</td>\n",
       "      <td id=\"T_55308_row4_col12\" class=\"data row4 col12\" >1.000000</td>\n",
       "      <td id=\"T_55308_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col15\" class=\"data row4 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col18\" class=\"data row4 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col19\" class=\"data row4 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col20\" class=\"data row4 col20\" >1.000000</td>\n",
       "      <td id=\"T_55308_row4_col21\" class=\"data row4 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col22\" class=\"data row4 col22\" >4.000000</td>\n",
       "      <td id=\"T_55308_row4_col23\" class=\"data row4 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col24\" class=\"data row4 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col25\" class=\"data row4 col25\" >3.000000</td>\n",
       "      <td id=\"T_55308_row4_col26\" class=\"data row4 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row4_col27\" class=\"data row4 col27\" >2.000000</td>\n",
       "      <td id=\"T_55308_row4_col28\" class=\"data row4 col28\" >str</td>\n",
       "      <td id=\"T_55308_row4_col29\" class=\"data row4 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row4_col30\" class=\"data row4 col30\" >650480.000000</td>\n",
       "      <td id=\"T_55308_row4_col31\" class=\"data row4 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row4_col32\" class=\"data row4 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row4_col33\" class=\"data row4 col33\" >56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row5\" class=\"row_heading level0 row5\" >166</th>\n",
       "      <td id=\"T_55308_row5_col0\" class=\"data row5 col0\" >69.92%</td>\n",
       "      <td id=\"T_55308_row5_col1\" class=\"data row5 col1\" >69.73%</td>\n",
       "      <td id=\"T_55308_row5_col2\" class=\"data row5 col2\" >70.46%</td>\n",
       "      <td id=\"T_55308_row5_col3\" class=\"data row5 col3\" >69.93%</td>\n",
       "      <td id=\"T_55308_row5_col4\" class=\"data row5 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col6\" class=\"data row5 col6\" >True</td>\n",
       "      <td id=\"T_55308_row5_col7\" class=\"data row5 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row5_col8\" class=\"data row5 col8\" >10.000000</td>\n",
       "      <td id=\"T_55308_row5_col9\" class=\"data row5 col9\" >162170.000000</td>\n",
       "      <td id=\"T_55308_row5_col10\" class=\"data row5 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row5_col11\" class=\"data row5 col11\" >2.000000</td>\n",
       "      <td id=\"T_55308_row5_col12\" class=\"data row5 col12\" >1.000000</td>\n",
       "      <td id=\"T_55308_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col15\" class=\"data row5 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row5_col16\" class=\"data row5 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col18\" class=\"data row5 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col19\" class=\"data row5 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col20\" class=\"data row5 col20\" >1.000000</td>\n",
       "      <td id=\"T_55308_row5_col21\" class=\"data row5 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col22\" class=\"data row5 col22\" >4.000000</td>\n",
       "      <td id=\"T_55308_row5_col23\" class=\"data row5 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col24\" class=\"data row5 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col25\" class=\"data row5 col25\" >3.000000</td>\n",
       "      <td id=\"T_55308_row5_col26\" class=\"data row5 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row5_col27\" class=\"data row5 col27\" >2.000000</td>\n",
       "      <td id=\"T_55308_row5_col28\" class=\"data row5 col28\" >str</td>\n",
       "      <td id=\"T_55308_row5_col29\" class=\"data row5 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row5_col30\" class=\"data row5 col30\" >650480.000000</td>\n",
       "      <td id=\"T_55308_row5_col31\" class=\"data row5 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row5_col32\" class=\"data row5 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row5_col33\" class=\"data row5 col33\" >253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row6\" class=\"row_heading level0 row6\" >176</th>\n",
       "      <td id=\"T_55308_row6_col0\" class=\"data row6 col0\" >68.72%</td>\n",
       "      <td id=\"T_55308_row6_col1\" class=\"data row6 col1\" >68.20%</td>\n",
       "      <td id=\"T_55308_row6_col2\" class=\"data row6 col2\" >70.04%</td>\n",
       "      <td id=\"T_55308_row6_col3\" class=\"data row6 col3\" >68.73%</td>\n",
       "      <td id=\"T_55308_row6_col4\" class=\"data row6 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row6_col5\" class=\"data row6 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col6\" class=\"data row6 col6\" >True</td>\n",
       "      <td id=\"T_55308_row6_col7\" class=\"data row6 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row6_col8\" class=\"data row6 col8\" >10.000000</td>\n",
       "      <td id=\"T_55308_row6_col9\" class=\"data row6 col9\" >162170.000000</td>\n",
       "      <td id=\"T_55308_row6_col10\" class=\"data row6 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row6_col11\" class=\"data row6 col11\" >2.000000</td>\n",
       "      <td id=\"T_55308_row6_col12\" class=\"data row6 col12\" >1.000000</td>\n",
       "      <td id=\"T_55308_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col15\" class=\"data row6 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row6_col16\" class=\"data row6 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col18\" class=\"data row6 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col19\" class=\"data row6 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col20\" class=\"data row6 col20\" >1.000000</td>\n",
       "      <td id=\"T_55308_row6_col21\" class=\"data row6 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col22\" class=\"data row6 col22\" >4.000000</td>\n",
       "      <td id=\"T_55308_row6_col23\" class=\"data row6 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col24\" class=\"data row6 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col25\" class=\"data row6 col25\" >3.000000</td>\n",
       "      <td id=\"T_55308_row6_col26\" class=\"data row6 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row6_col27\" class=\"data row6 col27\" >2.000000</td>\n",
       "      <td id=\"T_55308_row6_col28\" class=\"data row6 col28\" >str</td>\n",
       "      <td id=\"T_55308_row6_col29\" class=\"data row6 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row6_col30\" class=\"data row6 col30\" >650480.000000</td>\n",
       "      <td id=\"T_55308_row6_col31\" class=\"data row6 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row6_col32\" class=\"data row6 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row6_col33\" class=\"data row6 col33\" >53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row7\" class=\"row_heading level0 row7\" >184</th>\n",
       "      <td id=\"T_55308_row7_col0\" class=\"data row7 col0\" >65.42%</td>\n",
       "      <td id=\"T_55308_row7_col1\" class=\"data row7 col1\" >63.11%</td>\n",
       "      <td id=\"T_55308_row7_col2\" class=\"data row7 col2\" >70.65%</td>\n",
       "      <td id=\"T_55308_row7_col3\" class=\"data row7 col3\" >65.45%</td>\n",
       "      <td id=\"T_55308_row7_col4\" class=\"data row7 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row7_col5\" class=\"data row7 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col6\" class=\"data row7 col6\" >True</td>\n",
       "      <td id=\"T_55308_row7_col7\" class=\"data row7 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row7_col8\" class=\"data row7 col8\" >5.000000</td>\n",
       "      <td id=\"T_55308_row7_col9\" class=\"data row7 col9\" >174658.000000</td>\n",
       "      <td id=\"T_55308_row7_col10\" class=\"data row7 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col12\" class=\"data row7 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col15\" class=\"data row7 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row7_col16\" class=\"data row7 col16\" >2.000000</td>\n",
       "      <td id=\"T_55308_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col18\" class=\"data row7 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col19\" class=\"data row7 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col20\" class=\"data row7 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col21\" class=\"data row7 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col22\" class=\"data row7 col22\" >1.000000</td>\n",
       "      <td id=\"T_55308_row7_col23\" class=\"data row7 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col24\" class=\"data row7 col24\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col25\" class=\"data row7 col25\" >1.000000</td>\n",
       "      <td id=\"T_55308_row7_col26\" class=\"data row7 col26\" >2.000000</td>\n",
       "      <td id=\"T_55308_row7_col27\" class=\"data row7 col27\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col28\" class=\"data row7 col28\" >str</td>\n",
       "      <td id=\"T_55308_row7_col29\" class=\"data row7 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row7_col30\" class=\"data row7 col30\" >699936.000000</td>\n",
       "      <td id=\"T_55308_row7_col31\" class=\"data row7 col31\" >nan</td>\n",
       "      <td id=\"T_55308_row7_col32\" class=\"data row7 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row7_col33\" class=\"data row7 col33\" >52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row8\" class=\"row_heading level0 row8\" >226</th>\n",
       "      <td id=\"T_55308_row8_col0\" class=\"data row8 col0\" >50.05%</td>\n",
       "      <td id=\"T_55308_row8_col1\" class=\"data row8 col1\" >33.36%</td>\n",
       "      <td id=\"T_55308_row8_col2\" class=\"data row8 col2\" >25.03%</td>\n",
       "      <td id=\"T_55308_row8_col3\" class=\"data row8 col3\" >50.00%</td>\n",
       "      <td id=\"T_55308_row8_col4\" class=\"data row8 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row8_col5\" class=\"data row8 col5\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col6\" class=\"data row8 col6\" >True</td>\n",
       "      <td id=\"T_55308_row8_col7\" class=\"data row8 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row8_col8\" class=\"data row8 col8\" >4.000000</td>\n",
       "      <td id=\"T_55308_row8_col9\" class=\"data row8 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_55308_row8_col10\" class=\"data row8 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col12\" class=\"data row8 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col14\" class=\"data row8 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col15\" class=\"data row8 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row8_col16\" class=\"data row8 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col17\" class=\"data row8 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col18\" class=\"data row8 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col19\" class=\"data row8 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col20\" class=\"data row8 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col21\" class=\"data row8 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col22\" class=\"data row8 col22\" >2.000000</td>\n",
       "      <td id=\"T_55308_row8_col23\" class=\"data row8 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col24\" class=\"data row8 col24\" >1.000000</td>\n",
       "      <td id=\"T_55308_row8_col25\" class=\"data row8 col25\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col26\" class=\"data row8 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row8_col27\" class=\"data row8 col27\" >1.000000</td>\n",
       "      <td id=\"T_55308_row8_col28\" class=\"data row8 col28\" >str</td>\n",
       "      <td id=\"T_55308_row8_col29\" class=\"data row8 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row8_col30\" class=\"data row8 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_55308_row8_col31\" class=\"data row8 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row8_col32\" class=\"data row8 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row8_col33\" class=\"data row8 col33\" >54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row9\" class=\"row_heading level0 row9\" >227</th>\n",
       "      <td id=\"T_55308_row9_col0\" class=\"data row9 col0\" >50.05%</td>\n",
       "      <td id=\"T_55308_row9_col1\" class=\"data row9 col1\" >33.36%</td>\n",
       "      <td id=\"T_55308_row9_col2\" class=\"data row9 col2\" >25.03%</td>\n",
       "      <td id=\"T_55308_row9_col3\" class=\"data row9 col3\" >50.00%</td>\n",
       "      <td id=\"T_55308_row9_col4\" class=\"data row9 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row9_col5\" class=\"data row9 col5\" >True</td>\n",
       "      <td id=\"T_55308_row9_col6\" class=\"data row9 col6\" >True</td>\n",
       "      <td id=\"T_55308_row9_col7\" class=\"data row9 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row9_col8\" class=\"data row9 col8\" >4.000000</td>\n",
       "      <td id=\"T_55308_row9_col9\" class=\"data row9 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_55308_row9_col10\" class=\"data row9 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col12\" class=\"data row9 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col13\" class=\"data row9 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col14\" class=\"data row9 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col15\" class=\"data row9 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row9_col16\" class=\"data row9 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col17\" class=\"data row9 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col18\" class=\"data row9 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col19\" class=\"data row9 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col20\" class=\"data row9 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col21\" class=\"data row9 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col22\" class=\"data row9 col22\" >2.000000</td>\n",
       "      <td id=\"T_55308_row9_col23\" class=\"data row9 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col24\" class=\"data row9 col24\" >1.000000</td>\n",
       "      <td id=\"T_55308_row9_col25\" class=\"data row9 col25\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col26\" class=\"data row9 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row9_col27\" class=\"data row9 col27\" >1.000000</td>\n",
       "      <td id=\"T_55308_row9_col28\" class=\"data row9 col28\" >str</td>\n",
       "      <td id=\"T_55308_row9_col29\" class=\"data row9 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row9_col30\" class=\"data row9 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_55308_row9_col31\" class=\"data row9 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row9_col32\" class=\"data row9 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row9_col33\" class=\"data row9 col33\" >57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_55308_level0_row10\" class=\"row_heading level0 row10\" >229</th>\n",
       "      <td id=\"T_55308_row10_col0\" class=\"data row10 col0\" >50.05%</td>\n",
       "      <td id=\"T_55308_row10_col1\" class=\"data row10 col1\" >33.36%</td>\n",
       "      <td id=\"T_55308_row10_col2\" class=\"data row10 col2\" >25.03%</td>\n",
       "      <td id=\"T_55308_row10_col3\" class=\"data row10 col3\" >50.00%</td>\n",
       "      <td id=\"T_55308_row10_col4\" class=\"data row10 col4\" >keras</td>\n",
       "      <td id=\"T_55308_row10_col5\" class=\"data row10 col5\" >True</td>\n",
       "      <td id=\"T_55308_row10_col6\" class=\"data row10 col6\" >True</td>\n",
       "      <td id=\"T_55308_row10_col7\" class=\"data row10 col7\" >Sequential</td>\n",
       "      <td id=\"T_55308_row10_col8\" class=\"data row10 col8\" >4.000000</td>\n",
       "      <td id=\"T_55308_row10_col9\" class=\"data row10 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_55308_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_55308_row10_col11\" class=\"data row10 col11\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col12\" class=\"data row10 col12\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col13\" class=\"data row10 col13\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col14\" class=\"data row10 col14\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col15\" class=\"data row10 col15\" >1.000000</td>\n",
       "      <td id=\"T_55308_row10_col16\" class=\"data row10 col16\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col17\" class=\"data row10 col17\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col18\" class=\"data row10 col18\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col19\" class=\"data row10 col19\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col20\" class=\"data row10 col20\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col21\" class=\"data row10 col21\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col22\" class=\"data row10 col22\" >2.000000</td>\n",
       "      <td id=\"T_55308_row10_col23\" class=\"data row10 col23\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col24\" class=\"data row10 col24\" >1.000000</td>\n",
       "      <td id=\"T_55308_row10_col25\" class=\"data row10 col25\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col26\" class=\"data row10 col26\" >nan</td>\n",
       "      <td id=\"T_55308_row10_col27\" class=\"data row10 col27\" >1.000000</td>\n",
       "      <td id=\"T_55308_row10_col28\" class=\"data row10 col28\" >str</td>\n",
       "      <td id=\"T_55308_row10_col29\" class=\"data row10 col29\" >RMSprop</td>\n",
       "      <td id=\"T_55308_row10_col30\" class=\"data row10 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_55308_row10_col31\" class=\"data row10 col31\" >7.000000</td>\n",
       "      <td id=\"T_55308_row10_col32\" class=\"data row10 col32\" >lprockop</td>\n",
       "      <td id=\"T_55308_row10_col33\" class=\"data row10 col33\" >255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f64405516d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get leaderboard to explore current best model architectures\n",
    "\n",
    "# Get raw data in pandas data frame\n",
    "data = mycompetition.get_leaderboard()\n",
    "\n",
    "my_data = data[data['username'] == 'lprockop']\n",
    "\n",
    "# Stylize leaderboard data\n",
    "mycompetition.stylize_leaderboard(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "E11359Kn7ezH",
    "outputId": "0de79121-edb4-409d-f952-361b673b37a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-57fe9e81-9775-47fe-b7a2-a20a9ab6e925\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>transfer_learning</th>\n",
       "      <th>depth</th>\n",
       "      <th>conv1d_layers</th>\n",
       "      <th>maxpooling1d_layers</th>\n",
       "      <th>lstm_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.793633</td>\n",
       "      <td>0.792511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.792536</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.774973</td>\n",
       "      <td>0.774057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.763996</td>\n",
       "      <td>0.762342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.704720</td>\n",
       "      <td>0.700189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.699232</td>\n",
       "      <td>0.697288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.682001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.654226</td>\n",
       "      <td>0.631121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.333577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.333577</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.333577</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57fe9e81-9775-47fe-b7a2-a20a9ab6e925')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-57fe9e81-9775-47fe-b7a2-a20a9ab6e925 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-57fe9e81-9775-47fe-b7a2-a20a9ab6e925');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     accuracy  f1_score transfer_learning  depth  conv1d_layers  \\\n",
       "46   0.793633  0.792511               NaN    5.0            NaN   \n",
       "48   0.792536  0.790582               NaN    5.0            NaN   \n",
       "99   0.774973  0.774057               NaN    3.0            NaN   \n",
       "117  0.763996  0.762342               NaN    5.0            NaN   \n",
       "160  0.704720  0.700189               NaN   10.0            2.0   \n",
       "166  0.699232  0.697288               NaN   10.0            2.0   \n",
       "176  0.687157  0.682001               NaN   10.0            2.0   \n",
       "184  0.654226  0.631121               NaN    5.0            NaN   \n",
       "226  0.500549  0.333577               NaN    4.0            NaN   \n",
       "227  0.500549  0.333577              True    4.0            NaN   \n",
       "229  0.500549  0.333577              True    4.0            NaN   \n",
       "\n",
       "     maxpooling1d_layers  lstm_layers  \n",
       "46                   NaN          2.0  \n",
       "48                   NaN          2.0  \n",
       "99                   NaN          NaN  \n",
       "117                  NaN          NaN  \n",
       "160                  1.0          NaN  \n",
       "166                  1.0          NaN  \n",
       "176                  1.0          NaN  \n",
       "184                  NaN          2.0  \n",
       "226                  NaN          NaN  \n",
       "227                  NaN          NaN  \n",
       "229                  NaN          NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show differentiating model metrics to share with team\n",
    "\n",
    "my_data_smp = my_data[['accuracy', 'f1_score', 'transfer_learning', 'depth', 'conv1d_layers', 'maxpooling1d_layers', 'lstm_layers']]\n",
    "\n",
    "my_data_smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa-tluEbqRld"
   },
   "source": [
    "## Question 5: build 3 more models after team feedback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vryNbGsMaOE"
   },
   "source": [
    "### 5.1: Embedding layer and LSTM layers, more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP8vpWYyMaOF",
    "outputId": "79f8a755-a52c-47b8-b157-47c26a6d2f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "173/173 [==============================] - 13s 52ms/step - loss: 0.6552 - acc: 0.6189 - val_loss: 0.7457 - val_acc: 0.4993\n",
      "Epoch 2/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.5037 - acc: 0.7639 - val_loss: 0.8554 - val_acc: 0.5231\n",
      "Epoch 3/100\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.3851 - acc: 0.8344 - val_loss: 0.5498 - val_acc: 0.7507\n",
      "Epoch 4/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.3165 - acc: 0.8676 - val_loss: 0.5291 - val_acc: 0.7637\n",
      "Epoch 5/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.2666 - acc: 0.8913 - val_loss: 0.7667 - val_acc: 0.6553\n",
      "Epoch 6/100\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.2308 - acc: 0.9070 - val_loss: 0.6743 - val_acc: 0.7218\n",
      "Epoch 7/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.2061 - acc: 0.9174 - val_loss: 0.5687 - val_acc: 0.7529\n",
      "Epoch 8/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.1811 - acc: 0.9297 - val_loss: 0.6560 - val_acc: 0.7442\n",
      "Epoch 9/100\n",
      "173/173 [==============================] - 6s 34ms/step - loss: 0.1625 - acc: 0.9348 - val_loss: 0.5550 - val_acc: 0.7796\n",
      "Epoch 10/100\n",
      "173/173 [==============================] - 8s 44ms/step - loss: 0.1494 - acc: 0.9442 - val_loss: 0.5455 - val_acc: 0.7941\n",
      "Epoch 11/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.1340 - acc: 0.9471 - val_loss: 0.7558 - val_acc: 0.7276\n",
      "Epoch 12/100\n",
      "173/173 [==============================] - 6s 34ms/step - loss: 0.1239 - acc: 0.9556 - val_loss: 0.7160 - val_acc: 0.7269\n",
      "Epoch 13/100\n",
      "173/173 [==============================] - 8s 44ms/step - loss: 0.1178 - acc: 0.9563 - val_loss: 0.7508 - val_acc: 0.7543\n",
      "Epoch 14/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.1089 - acc: 0.9581 - val_loss: 0.7907 - val_acc: 0.7442\n",
      "Epoch 15/100\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.1073 - acc: 0.9604 - val_loss: 0.8118 - val_acc: 0.7175\n",
      "Epoch 16/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0942 - acc: 0.9641 - val_loss: 0.9475 - val_acc: 0.6944\n",
      "Epoch 17/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0897 - acc: 0.9666 - val_loss: 0.8239 - val_acc: 0.7298\n",
      "Epoch 18/100\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.0831 - acc: 0.9688 - val_loss: 0.7880 - val_acc: 0.7522\n",
      "Epoch 19/100\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.0796 - acc: 0.9704 - val_loss: 0.9596 - val_acc: 0.7276\n",
      "Epoch 20/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0746 - acc: 0.9720 - val_loss: 0.9874 - val_acc: 0.7197\n",
      "Epoch 21/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0701 - acc: 0.9733 - val_loss: 0.7588 - val_acc: 0.7811\n",
      "Epoch 22/100\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.0697 - acc: 0.9734 - val_loss: 1.1473 - val_acc: 0.7103\n",
      "Epoch 23/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0643 - acc: 0.9771 - val_loss: 1.0533 - val_acc: 0.7298\n",
      "Epoch 24/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0622 - acc: 0.9785 - val_loss: 1.0083 - val_acc: 0.7392\n",
      "Epoch 25/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0603 - acc: 0.9776 - val_loss: 1.2596 - val_acc: 0.7153\n",
      "Epoch 26/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0594 - acc: 0.9799 - val_loss: 0.8596 - val_acc: 0.7710\n",
      "Epoch 27/100\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.0591 - acc: 0.9787 - val_loss: 1.1305 - val_acc: 0.7327\n",
      "Epoch 28/100\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.0547 - acc: 0.9803 - val_loss: 1.0085 - val_acc: 0.7457\n",
      "Epoch 29/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0534 - acc: 0.9810 - val_loss: 0.9785 - val_acc: 0.7551\n",
      "Epoch 30/100\n",
      "173/173 [==============================] - 7s 42ms/step - loss: 0.0473 - acc: 0.9818 - val_loss: 1.0394 - val_acc: 0.7601\n",
      "Epoch 31/100\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.0496 - acc: 0.9805 - val_loss: 0.9196 - val_acc: 0.7623\n",
      "Epoch 32/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0494 - acc: 0.9828 - val_loss: 1.2240 - val_acc: 0.7247\n",
      "Epoch 33/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0420 - acc: 0.9854 - val_loss: 1.1320 - val_acc: 0.7608\n",
      "Epoch 34/100\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.0437 - acc: 0.9836 - val_loss: 1.0801 - val_acc: 0.7406\n",
      "Epoch 35/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0420 - acc: 0.9846 - val_loss: 0.9435 - val_acc: 0.7825\n",
      "Epoch 36/100\n",
      "173/173 [==============================] - 8s 46ms/step - loss: 0.0417 - acc: 0.9850 - val_loss: 1.0785 - val_acc: 0.7601\n",
      "Epoch 37/100\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.0406 - acc: 0.9861 - val_loss: 0.9896 - val_acc: 0.7767\n",
      "Epoch 38/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0373 - acc: 0.9879 - val_loss: 1.1561 - val_acc: 0.7536\n",
      "Epoch 39/100\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.0394 - acc: 0.9863 - val_loss: 1.1349 - val_acc: 0.7623\n",
      "Epoch 40/100\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.0379 - acc: 0.9866 - val_loss: 1.1915 - val_acc: 0.7529\n",
      "Epoch 41/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0362 - acc: 0.9879 - val_loss: 0.9407 - val_acc: 0.7818\n",
      "Epoch 42/100\n",
      "173/173 [==============================] - 8s 48ms/step - loss: 0.0341 - acc: 0.9899 - val_loss: 1.1090 - val_acc: 0.7594\n",
      "Epoch 43/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0319 - acc: 0.9892 - val_loss: 1.3352 - val_acc: 0.7478\n",
      "Epoch 44/100\n",
      "173/173 [==============================] - 6s 34ms/step - loss: 0.0350 - acc: 0.9877 - val_loss: 1.1147 - val_acc: 0.7775\n",
      "Epoch 45/100\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.0303 - acc: 0.9883 - val_loss: 1.2577 - val_acc: 0.7652\n",
      "Epoch 46/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0301 - acc: 0.9892 - val_loss: 1.0342 - val_acc: 0.7753\n",
      "Epoch 47/100\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.0285 - acc: 0.9908 - val_loss: 1.4757 - val_acc: 0.7334\n",
      "Epoch 48/100\n",
      "173/173 [==============================] - 10s 60ms/step - loss: 0.0290 - acc: 0.9899 - val_loss: 1.1677 - val_acc: 0.7652\n",
      "Epoch 49/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0280 - acc: 0.9897 - val_loss: 1.2915 - val_acc: 0.7565\n",
      "Epoch 50/100\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.0275 - acc: 0.9901 - val_loss: 1.3067 - val_acc: 0.7558\n",
      "Epoch 51/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.0269 - acc: 0.9919 - val_loss: 1.2922 - val_acc: 0.7529\n",
      "Epoch 52/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0265 - acc: 0.9906 - val_loss: 1.2509 - val_acc: 0.7377\n",
      "Epoch 53/100\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.0271 - acc: 0.9919 - val_loss: 1.3165 - val_acc: 0.7478\n",
      "Epoch 54/100\n",
      "173/173 [==============================] - 8s 43ms/step - loss: 0.0250 - acc: 0.9917 - val_loss: 1.3339 - val_acc: 0.7319\n",
      "Epoch 55/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0239 - acc: 0.9913 - val_loss: 1.3727 - val_acc: 0.7616\n",
      "Epoch 56/100\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.0221 - acc: 0.9924 - val_loss: 1.3025 - val_acc: 0.7645\n",
      "Epoch 57/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0232 - acc: 0.9924 - val_loss: 1.5073 - val_acc: 0.7377\n",
      "Epoch 58/100\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.0241 - acc: 0.9931 - val_loss: 1.2081 - val_acc: 0.7623\n",
      "Epoch 59/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0223 - acc: 0.9919 - val_loss: 1.2449 - val_acc: 0.7579\n",
      "Epoch 60/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0216 - acc: 0.9931 - val_loss: 1.1288 - val_acc: 0.7746\n",
      "Epoch 61/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0219 - acc: 0.9928 - val_loss: 1.2921 - val_acc: 0.7746\n",
      "Epoch 62/100\n",
      "173/173 [==============================] - 7s 42ms/step - loss: 0.0204 - acc: 0.9921 - val_loss: 1.2669 - val_acc: 0.7579\n",
      "Epoch 63/100\n",
      "173/173 [==============================] - 7s 38ms/step - loss: 0.0204 - acc: 0.9930 - val_loss: 1.3764 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 1.5324 - val_acc: 0.7384\n",
      "Epoch 65/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0185 - acc: 0.9928 - val_loss: 1.1181 - val_acc: 0.8006\n",
      "Epoch 66/100\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.0177 - acc: 0.9942 - val_loss: 1.2579 - val_acc: 0.7767\n",
      "Epoch 67/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0180 - acc: 0.9939 - val_loss: 1.4170 - val_acc: 0.7543\n",
      "Epoch 68/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.0167 - acc: 0.9957 - val_loss: 1.4224 - val_acc: 0.7579\n",
      "Epoch 69/100\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.0148 - acc: 0.9942 - val_loss: 1.5563 - val_acc: 0.7558\n",
      "Epoch 70/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0181 - acc: 0.9940 - val_loss: 1.6382 - val_acc: 0.7319\n",
      "Epoch 71/100\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.0149 - acc: 0.9942 - val_loss: 1.4766 - val_acc: 0.7493\n",
      "Epoch 72/100\n",
      "173/173 [==============================] - 6s 34ms/step - loss: 0.0126 - acc: 0.9946 - val_loss: 1.6195 - val_acc: 0.7413\n",
      "Epoch 73/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0158 - acc: 0.9944 - val_loss: 1.7004 - val_acc: 0.7355\n",
      "Epoch 74/100\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 1.5698 - val_acc: 0.7449\n",
      "Epoch 75/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0140 - acc: 0.9949 - val_loss: 1.4306 - val_acc: 0.7623\n",
      "Epoch 76/100\n",
      "173/173 [==============================] - 6s 34ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 1.3768 - val_acc: 0.7673\n",
      "Epoch 77/100\n",
      "173/173 [==============================] - 8s 47ms/step - loss: 0.0160 - acc: 0.9948 - val_loss: 1.7399 - val_acc: 0.7225\n",
      "Epoch 78/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0115 - acc: 0.9966 - val_loss: 1.4329 - val_acc: 0.7818\n",
      "Epoch 79/100\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 1.6204 - val_acc: 0.7421\n",
      "Epoch 80/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.0105 - acc: 0.9962 - val_loss: 1.5764 - val_acc: 0.7457\n",
      "Epoch 81/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 1.4009 - val_acc: 0.7738\n",
      "Epoch 82/100\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 1.4096 - val_acc: 0.7767\n",
      "Epoch 83/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0101 - acc: 0.9960 - val_loss: 1.6644 - val_acc: 0.7514\n",
      "Epoch 84/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 1.5841 - val_acc: 0.7594\n",
      "Epoch 85/100\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 1.4898 - val_acc: 0.7616\n",
      "Epoch 86/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 1.6242 - val_acc: 0.7753\n",
      "Epoch 87/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0089 - acc: 0.9960 - val_loss: 1.5614 - val_acc: 0.7601\n",
      "Epoch 88/100\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 1.9458 - val_acc: 0.7262\n",
      "Epoch 89/100\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 1.5648 - val_acc: 0.7746\n",
      "Epoch 90/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 1.5709 - val_acc: 0.7673\n",
      "Epoch 91/100\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 1.6470 - val_acc: 0.7608\n",
      "Epoch 92/100\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 1.6998 - val_acc: 0.7428\n",
      "Epoch 93/100\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.0091 - acc: 0.9966 - val_loss: 1.7987 - val_acc: 0.7327\n",
      "Epoch 94/100\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 1.8122 - val_acc: 0.7464\n",
      "Epoch 95/100\n",
      "173/173 [==============================] - 7s 38ms/step - loss: 0.0071 - acc: 0.9971 - val_loss: 1.6478 - val_acc: 0.7688\n",
      "Epoch 96/100\n",
      "173/173 [==============================] - 5s 32ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 1.9605 - val_acc: 0.7435\n",
      "Epoch 97/100\n",
      "173/173 [==============================] - 8s 45ms/step - loss: 0.0060 - acc: 0.9978 - val_loss: 1.7307 - val_acc: 0.7514\n",
      "Epoch 98/100\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.0065 - acc: 0.9973 - val_loss: 1.7900 - val_acc: 0.7529\n",
      "Epoch 99/100\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.0036 - acc: 0.9986 - val_loss: 2.4497 - val_acc: 0.7103\n",
      "Epoch 100/100\n",
      "173/173 [==============================] - 8s 48ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 2.2028 - val_acc: 0.7283\n"
     ]
    }
   ],
   "source": [
    "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(10000, 16, input_length=40))\n",
    "model5.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model5.add(LSTM(32, dropout=0.2))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model5.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzoBp6NHMaOG"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model5, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model5.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp8nu2UTMaOG",
    "outputId": "01069bcf-8e7d-4171-9a4c-c2fd3e911bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 11ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 256\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#submit model\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model5.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model5.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLlmNEIsMsJN"
   },
   "source": [
    "### 5.2: Embedding layer and Conv1d layers, more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvJJ4H3mMsJd",
    "outputId": "a810d01d-c868-481d-be71-9e13ba5b5744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 37, 16)            1040      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1, 16)             1040      \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,170\n",
      "Trainable params: 162,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "195/195 [==============================] - 3s 8ms/step - loss: 0.6895 - acc: 0.5453 - val_loss: 0.7448 - val_acc: 0.2283\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6874 - acc: 0.5543 - val_loss: 0.7614 - val_acc: 0.2283\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.6870 - acc: 0.5543 - val_loss: 0.7504 - val_acc: 0.2283\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.6763 - acc: 0.5543 - val_loss: 0.7392 - val_acc: 0.2283\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.6310 - acc: 0.6501 - val_loss: 0.7054 - val_acc: 0.5723\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.5563 - acc: 0.8447 - val_loss: 0.6788 - val_acc: 0.5968\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.4700 - acc: 0.8717 - val_loss: 0.6423 - val_acc: 0.6156\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.3915 - acc: 0.8924 - val_loss: 0.7148 - val_acc: 0.5737\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.3257 - acc: 0.9054 - val_loss: 0.6317 - val_acc: 0.6879\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.2776 - acc: 0.9146 - val_loss: 0.6708 - val_acc: 0.6272\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.2419 - acc: 0.9208 - val_loss: 0.6923 - val_acc: 0.6647\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.2139 - acc: 0.9279 - val_loss: 0.6569 - val_acc: 0.6965\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.1950 - acc: 0.9313 - val_loss: 0.8018 - val_acc: 0.5824\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.1768 - acc: 0.9346 - val_loss: 0.7268 - val_acc: 0.6792\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.1632 - acc: 0.9425 - val_loss: 0.8374 - val_acc: 0.5896\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1543 - acc: 0.9420 - val_loss: 0.7307 - val_acc: 0.6980\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1436 - acc: 0.9420 - val_loss: 0.8581 - val_acc: 0.5896\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1341 - acc: 0.9470 - val_loss: 0.7941 - val_acc: 0.6734\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1251 - acc: 0.9457 - val_loss: 0.8032 - val_acc: 0.6040\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1183 - acc: 0.9513 - val_loss: 0.8696 - val_acc: 0.6012\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1120 - acc: 0.9522 - val_loss: 0.9527 - val_acc: 0.6488\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.1094 - acc: 0.9497 - val_loss: 0.8571 - val_acc: 0.6142\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.1026 - acc: 0.9562 - val_loss: 0.9445 - val_acc: 0.5867\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0971 - acc: 0.9558 - val_loss: 0.9745 - val_acc: 0.5954\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0906 - acc: 0.9576 - val_loss: 1.0192 - val_acc: 0.5925\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0880 - acc: 0.9587 - val_loss: 0.8959 - val_acc: 0.6691\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0856 - acc: 0.9587 - val_loss: 0.9723 - val_acc: 0.5925\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0837 - acc: 0.9573 - val_loss: 1.0559 - val_acc: 0.5838\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0810 - acc: 0.9607 - val_loss: 1.0365 - val_acc: 0.6431\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0779 - acc: 0.9621 - val_loss: 0.9771 - val_acc: 0.6532\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0749 - acc: 0.9618 - val_loss: 0.9789 - val_acc: 0.6633\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0720 - acc: 0.9618 - val_loss: 1.0725 - val_acc: 0.5809\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0719 - acc: 0.9600 - val_loss: 1.1334 - val_acc: 0.5694\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0700 - acc: 0.9636 - val_loss: 1.2198 - val_acc: 0.5535\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0682 - acc: 0.9626 - val_loss: 1.1477 - val_acc: 0.6257\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.0659 - acc: 0.9637 - val_loss: 1.1965 - val_acc: 0.5665\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0664 - acc: 0.9634 - val_loss: 1.2455 - val_acc: 0.6069\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0649 - acc: 0.9648 - val_loss: 1.2141 - val_acc: 0.5549\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0643 - acc: 0.9613 - val_loss: 1.1824 - val_acc: 0.6286\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0636 - acc: 0.9632 - val_loss: 1.3322 - val_acc: 0.5405\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0631 - acc: 0.9639 - val_loss: 1.1607 - val_acc: 0.6416\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0620 - acc: 0.9640 - val_loss: 1.2653 - val_acc: 0.5607\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.0633 - acc: 0.9637 - val_loss: 1.1657 - val_acc: 0.5838\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.0621 - acc: 0.9647 - val_loss: 1.2223 - val_acc: 0.5751\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0611 - acc: 0.9631 - val_loss: 1.2284 - val_acc: 0.5665\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9636 - val_loss: 1.2139 - val_acc: 0.5723\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0614 - acc: 0.9642 - val_loss: 1.1799 - val_acc: 0.6488\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0610 - acc: 0.9658 - val_loss: 1.1668 - val_acc: 0.5780\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0609 - acc: 0.9653 - val_loss: 1.2121 - val_acc: 0.5795\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 1s 4ms/step - loss: 0.0603 - acc: 0.9634 - val_loss: 1.1279 - val_acc: 0.5939\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(10000, 16, input_length=40))\n",
    "model6.add(layers.Conv1D(16, 4, activation='relu')) \n",
    "model6.add(layers.MaxPooling1D(8))\n",
    "model6.add(layers.Conv1D(16, 4, activation='relu'))\n",
    "model6.add(layers.GlobalMaxPooling1D())\n",
    "model6.add(layers.Dense(4))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(2, activation='softmax'))\n",
    "model6.add(Dense(2, activation='softmax'))\n",
    "model6.add(Dense(2, activation='softmax'))\n",
    "model6.summary()\n",
    "\n",
    "model6.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model6.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuTZ3m4rMsJd"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model6, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model6.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjnFaWrbMsJd",
    "outputId": "9c605e97-edcf-4017-df97-1308e381fba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 258\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# Submit model\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model6.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model6.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqb4yYemMwYt"
   },
   "source": [
    "### 5.3: Transfer learning with glove embeddings, more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uo4rOj9OMwYt"
   },
   "outputs": [],
   "source": [
    "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
    "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
    "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qzzlr3FJMwYu"
   },
   "outputs": [],
   "source": [
    "! unzip glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PgAkEEKMwYu",
    "outputId": "a293b32c-9f6d-4eea-9ac5-cb84b62263be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding data for 100 feature embedding matrix\n",
    "import os\n",
    "glove_dir = os.getcwd()\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# Tokenize the data into one hot vectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100  # We will cut reviews after 100 words in sequence\n",
    "training_samples = 10000  # We will be training on 10000 samples\n",
    "validation_samples = 10000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHKNNcW8MwYu",
    "outputId": "2253f3e6-50fd-4f05-8494-5bf870a267e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13835 unique tokens.\n",
      "Shape of data tensor: (6920, 100)\n",
      "Shape of label tensor: (6920,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train) # converts words in each text to each word's numeric index in tokenizer dictionary.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "labels = np.asarray(y_train['Negative'])\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-IzCisuMwYv"
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a validation set\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "X_train_1 = data[:training_samples] #100 words\n",
    "y_train_1 = labels[:training_samples]\n",
    "X_val_1 = data[training_samples: training_samples + validation_samples]\n",
    "y_val_1 = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZMoJdQzMwYv"
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_dim = 100 # change if you use txt files using larger number of features\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AZDIzMhMwYv",
    "outputId": "b79e1953-2bee-4382-f59e-03d70921ba61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                320032    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "433/433 [==============================] - 4s 8ms/step - loss: 0.6256 - acc: 0.6517\n",
      "Epoch 2/50\n",
      "433/433 [==============================] - 3s 6ms/step - loss: 0.4935 - acc: 0.7585\n",
      "Epoch 3/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.4047 - acc: 0.8113\n",
      "Epoch 4/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.3103 - acc: 0.8686\n",
      "Epoch 5/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 0.2285 - acc: 0.9092\n",
      "Epoch 6/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1577 - acc: 0.9439\n",
      "Epoch 7/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 0.1059 - acc: 0.9675\n",
      "Epoch 8/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0702 - acc: 0.9803\n",
      "Epoch 9/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0452 - acc: 0.9892\n",
      "Epoch 10/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0283 - acc: 0.9935\n",
      "Epoch 11/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.0177 - acc: 0.9970\n",
      "Epoch 12/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.0108 - acc: 0.9981\n",
      "Epoch 13/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 14/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.0044 - acc: 0.9994\n",
      "Epoch 15/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 16/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 17/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 18/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 0.0010 - acc: 0.9999\n",
      "Epoch 19/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 6.0782e-04 - acc: 0.9999\n",
      "Epoch 20/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 5.3395e-04 - acc: 0.9999\n",
      "Epoch 21/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 3.5214e-04 - acc: 0.9999\n",
      "Epoch 22/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.9503e-04 - acc: 0.9999\n",
      "Epoch 23/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 3.4202e-04 - acc: 0.9999\n",
      "Epoch 24/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.5474e-04 - acc: 0.9999\n",
      "Epoch 25/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.3468e-04 - acc: 0.9999\n",
      "Epoch 26/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.3912e-04 - acc: 0.9999\n",
      "Epoch 27/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.3869e-04 - acc: 0.9999\n",
      "Epoch 28/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.2170e-04 - acc: 0.9999\n",
      "Epoch 29/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.2421e-04 - acc: 0.9999\n",
      "Epoch 30/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.2768e-04 - acc: 0.9999\n",
      "Epoch 31/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2085e-04 - acc: 0.9999\n",
      "Epoch 32/50\n",
      "433/433 [==============================] - 2s 6ms/step - loss: 2.2292e-04 - acc: 0.9999\n",
      "Epoch 33/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.2396e-04 - acc: 0.9999\n",
      "Epoch 34/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.2341e-04 - acc: 0.9999\n",
      "Epoch 35/50\n",
      "433/433 [==============================] - 3s 6ms/step - loss: 2.2295e-04 - acc: 0.9999\n",
      "Epoch 36/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.2262e-04 - acc: 0.9999\n",
      "Epoch 37/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.1891e-04 - acc: 0.9999\n",
      "Epoch 38/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2278e-04 - acc: 0.9999\n",
      "Epoch 39/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.1843e-04 - acc: 0.9999\n",
      "Epoch 40/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2095e-04 - acc: 0.9999\n",
      "Epoch 41/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.2138e-04 - acc: 0.9999\n",
      "Epoch 42/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.2110e-04 - acc: 0.9999\n",
      "Epoch 43/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.2091e-04 - acc: 0.9999\n",
      "Epoch 44/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2086e-04 - acc: 0.9999\n",
      "Epoch 45/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.1756e-04 - acc: 0.9999\n",
      "Epoch 46/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2112e-04 - acc: 0.9999\n",
      "Epoch 47/50\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 2.2193e-04 - acc: 0.9999\n",
      "Epoch 48/50\n",
      "433/433 [==============================] - 2s 5ms/step - loss: 2.2199e-04 - acc: 0.9999\n",
      "Epoch 49/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.1823e-04 - acc: 0.9999\n",
      "Epoch 50/50\n",
      "433/433 [==============================] - 3s 7ms/step - loss: 2.1833e-04 - acc: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
    "from tensorflow.keras.layers import Dense, Embedding,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "model7 = tf.keras.Sequential()\n",
    "model7.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model7.add(tf.keras.layers.Flatten())\n",
    "model7.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model7.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model7.summary()\n",
    "\n",
    "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
    "model7.layers[0].set_weights([embedding_matrix])\n",
    "model7.layers[0].trainable = False\n",
    "\n",
    "model7.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model7.fit(X_train_1, y_train_1,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_val_1, y_val_1))\n",
    "model7.save_weights('pre_trained_glove_model.h5')\n",
    "\n",
    "# Training data small to speed up training. Increase for better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOwUqa6gMwYv"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model7, framework='keras',\n",
    "                          transfer_learning=True,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model7.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlM0OmBsMwYw",
    "outputId": "e3fb9f95-d3f0-4ab5-8597-d531e77ef213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 3ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 259\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "# submit model\n",
    "\n",
    "#using tokenizer object we fit to test data above\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_1 = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model7.predict(X_test_1).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model7.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels,\n",
    "                           custom_metadata = {'team': 7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfVtbafvqV3d"
   },
   "source": [
    "## Question 6: Discuss results & Question 7: Discuss which models I tried, which performed better, relevant hyper-params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb4NO5LC5c4T"
   },
   "source": [
    "My team recommended I try to improve model performance by increasing the number of epochs on the models I had already run. \n",
    "\n",
    "When increasing the epochs in the Sequential model (depth of 5, including 1 embedding layer and 2 LSTM layers and no conv1d layers' RMS optimizer) from 10 to 100, the f1 score improved from 79.09% to 79.25%. This architecture remained my best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "AtR5ZhY24v6D",
    "outputId": "c6fd3f9d-c2e2-483e-e989-bcef2c3dd8e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_16ba8_row0_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 79.4%, transparent 79.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row0_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row0_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 80.0%, transparent 80.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row0_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 79.4%, transparent 79.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row0_col4, #T_16ba8_row0_col5, #T_16ba8_row0_col6, #T_16ba8_row0_col7, #T_16ba8_row0_col8, #T_16ba8_row0_col9, #T_16ba8_row0_col10, #T_16ba8_row0_col11, #T_16ba8_row0_col12, #T_16ba8_row0_col13, #T_16ba8_row0_col14, #T_16ba8_row0_col15, #T_16ba8_row0_col16, #T_16ba8_row0_col17, #T_16ba8_row0_col18, #T_16ba8_row0_col19, #T_16ba8_row0_col20, #T_16ba8_row0_col21, #T_16ba8_row0_col22, #T_16ba8_row0_col23, #T_16ba8_row0_col24, #T_16ba8_row0_col25, #T_16ba8_row0_col26, #T_16ba8_row0_col27, #T_16ba8_row0_col28, #T_16ba8_row0_col29, #T_16ba8_row0_col30, #T_16ba8_row0_col31, #T_16ba8_row0_col32, #T_16ba8_row0_col33, #T_16ba8_row1_col4, #T_16ba8_row1_col5, #T_16ba8_row1_col6, #T_16ba8_row1_col7, #T_16ba8_row1_col8, #T_16ba8_row1_col9, #T_16ba8_row1_col10, #T_16ba8_row1_col11, #T_16ba8_row1_col12, #T_16ba8_row1_col13, #T_16ba8_row1_col14, #T_16ba8_row1_col15, #T_16ba8_row1_col16, #T_16ba8_row1_col17, #T_16ba8_row1_col18, #T_16ba8_row1_col19, #T_16ba8_row1_col20, #T_16ba8_row1_col21, #T_16ba8_row1_col22, #T_16ba8_row1_col23, #T_16ba8_row1_col24, #T_16ba8_row1_col25, #T_16ba8_row1_col26, #T_16ba8_row1_col27, #T_16ba8_row1_col28, #T_16ba8_row1_col29, #T_16ba8_row1_col30, #T_16ba8_row1_col31, #T_16ba8_row1_col32, #T_16ba8_row1_col33, #T_16ba8_row2_col4, #T_16ba8_row2_col5, #T_16ba8_row2_col6, #T_16ba8_row2_col7, #T_16ba8_row2_col8, #T_16ba8_row2_col9, #T_16ba8_row2_col10, #T_16ba8_row2_col11, #T_16ba8_row2_col12, #T_16ba8_row2_col13, #T_16ba8_row2_col14, #T_16ba8_row2_col15, #T_16ba8_row2_col16, #T_16ba8_row2_col17, #T_16ba8_row2_col18, #T_16ba8_row2_col19, #T_16ba8_row2_col20, #T_16ba8_row2_col21, #T_16ba8_row2_col22, #T_16ba8_row2_col23, #T_16ba8_row2_col24, #T_16ba8_row2_col25, #T_16ba8_row2_col26, #T_16ba8_row2_col27, #T_16ba8_row2_col28, #T_16ba8_row2_col29, #T_16ba8_row2_col30, #T_16ba8_row2_col31, #T_16ba8_row2_col32, #T_16ba8_row2_col33, #T_16ba8_row3_col4, #T_16ba8_row3_col5, #T_16ba8_row3_col6, #T_16ba8_row3_col7, #T_16ba8_row3_col8, #T_16ba8_row3_col9, #T_16ba8_row3_col10, #T_16ba8_row3_col11, #T_16ba8_row3_col12, #T_16ba8_row3_col13, #T_16ba8_row3_col14, #T_16ba8_row3_col15, #T_16ba8_row3_col16, #T_16ba8_row3_col17, #T_16ba8_row3_col18, #T_16ba8_row3_col19, #T_16ba8_row3_col20, #T_16ba8_row3_col21, #T_16ba8_row3_col22, #T_16ba8_row3_col23, #T_16ba8_row3_col24, #T_16ba8_row3_col25, #T_16ba8_row3_col26, #T_16ba8_row3_col27, #T_16ba8_row3_col28, #T_16ba8_row3_col29, #T_16ba8_row3_col30, #T_16ba8_row3_col31, #T_16ba8_row3_col32, #T_16ba8_row3_col33, #T_16ba8_row4_col4, #T_16ba8_row4_col5, #T_16ba8_row4_col6, #T_16ba8_row4_col7, #T_16ba8_row4_col8, #T_16ba8_row4_col9, #T_16ba8_row4_col10, #T_16ba8_row4_col11, #T_16ba8_row4_col12, #T_16ba8_row4_col13, #T_16ba8_row4_col14, #T_16ba8_row4_col15, #T_16ba8_row4_col16, #T_16ba8_row4_col17, #T_16ba8_row4_col18, #T_16ba8_row4_col19, #T_16ba8_row4_col20, #T_16ba8_row4_col21, #T_16ba8_row4_col22, #T_16ba8_row4_col23, #T_16ba8_row4_col24, #T_16ba8_row4_col25, #T_16ba8_row4_col26, #T_16ba8_row4_col27, #T_16ba8_row4_col28, #T_16ba8_row4_col29, #T_16ba8_row4_col30, #T_16ba8_row4_col31, #T_16ba8_row4_col32, #T_16ba8_row4_col33, #T_16ba8_row5_col4, #T_16ba8_row5_col5, #T_16ba8_row5_col6, #T_16ba8_row5_col7, #T_16ba8_row5_col8, #T_16ba8_row5_col9, #T_16ba8_row5_col10, #T_16ba8_row5_col11, #T_16ba8_row5_col12, #T_16ba8_row5_col13, #T_16ba8_row5_col14, #T_16ba8_row5_col15, #T_16ba8_row5_col16, #T_16ba8_row5_col17, #T_16ba8_row5_col18, #T_16ba8_row5_col19, #T_16ba8_row5_col20, #T_16ba8_row5_col21, #T_16ba8_row5_col22, #T_16ba8_row5_col23, #T_16ba8_row5_col24, #T_16ba8_row5_col25, #T_16ba8_row5_col26, #T_16ba8_row5_col27, #T_16ba8_row5_col28, #T_16ba8_row5_col29, #T_16ba8_row5_col30, #T_16ba8_row5_col31, #T_16ba8_row5_col32, #T_16ba8_row5_col33, #T_16ba8_row6_col4, #T_16ba8_row6_col5, #T_16ba8_row6_col6, #T_16ba8_row6_col7, #T_16ba8_row6_col8, #T_16ba8_row6_col9, #T_16ba8_row6_col10, #T_16ba8_row6_col11, #T_16ba8_row6_col12, #T_16ba8_row6_col13, #T_16ba8_row6_col14, #T_16ba8_row6_col15, #T_16ba8_row6_col16, #T_16ba8_row6_col17, #T_16ba8_row6_col18, #T_16ba8_row6_col19, #T_16ba8_row6_col20, #T_16ba8_row6_col21, #T_16ba8_row6_col22, #T_16ba8_row6_col23, #T_16ba8_row6_col24, #T_16ba8_row6_col25, #T_16ba8_row6_col26, #T_16ba8_row6_col27, #T_16ba8_row6_col28, #T_16ba8_row6_col29, #T_16ba8_row6_col30, #T_16ba8_row6_col31, #T_16ba8_row6_col32, #T_16ba8_row6_col33, #T_16ba8_row7_col4, #T_16ba8_row7_col5, #T_16ba8_row7_col6, #T_16ba8_row7_col7, #T_16ba8_row7_col8, #T_16ba8_row7_col9, #T_16ba8_row7_col10, #T_16ba8_row7_col11, #T_16ba8_row7_col12, #T_16ba8_row7_col13, #T_16ba8_row7_col14, #T_16ba8_row7_col15, #T_16ba8_row7_col16, #T_16ba8_row7_col17, #T_16ba8_row7_col18, #T_16ba8_row7_col19, #T_16ba8_row7_col20, #T_16ba8_row7_col21, #T_16ba8_row7_col22, #T_16ba8_row7_col23, #T_16ba8_row7_col24, #T_16ba8_row7_col25, #T_16ba8_row7_col26, #T_16ba8_row7_col27, #T_16ba8_row7_col28, #T_16ba8_row7_col29, #T_16ba8_row7_col30, #T_16ba8_row7_col31, #T_16ba8_row7_col32, #T_16ba8_row7_col33, #T_16ba8_row8_col4, #T_16ba8_row8_col5, #T_16ba8_row8_col6, #T_16ba8_row8_col7, #T_16ba8_row8_col8, #T_16ba8_row8_col9, #T_16ba8_row8_col10, #T_16ba8_row8_col11, #T_16ba8_row8_col12, #T_16ba8_row8_col13, #T_16ba8_row8_col14, #T_16ba8_row8_col15, #T_16ba8_row8_col16, #T_16ba8_row8_col17, #T_16ba8_row8_col18, #T_16ba8_row8_col19, #T_16ba8_row8_col20, #T_16ba8_row8_col21, #T_16ba8_row8_col22, #T_16ba8_row8_col23, #T_16ba8_row8_col24, #T_16ba8_row8_col25, #T_16ba8_row8_col26, #T_16ba8_row8_col27, #T_16ba8_row8_col28, #T_16ba8_row8_col29, #T_16ba8_row8_col30, #T_16ba8_row8_col31, #T_16ba8_row8_col32, #T_16ba8_row8_col33, #T_16ba8_row9_col4, #T_16ba8_row9_col5, #T_16ba8_row9_col6, #T_16ba8_row9_col7, #T_16ba8_row9_col8, #T_16ba8_row9_col9, #T_16ba8_row9_col10, #T_16ba8_row9_col11, #T_16ba8_row9_col12, #T_16ba8_row9_col13, #T_16ba8_row9_col14, #T_16ba8_row9_col15, #T_16ba8_row9_col16, #T_16ba8_row9_col17, #T_16ba8_row9_col18, #T_16ba8_row9_col19, #T_16ba8_row9_col20, #T_16ba8_row9_col21, #T_16ba8_row9_col22, #T_16ba8_row9_col23, #T_16ba8_row9_col24, #T_16ba8_row9_col25, #T_16ba8_row9_col26, #T_16ba8_row9_col27, #T_16ba8_row9_col28, #T_16ba8_row9_col29, #T_16ba8_row9_col30, #T_16ba8_row9_col31, #T_16ba8_row9_col32, #T_16ba8_row9_col33, #T_16ba8_row10_col4, #T_16ba8_row10_col5, #T_16ba8_row10_col6, #T_16ba8_row10_col7, #T_16ba8_row10_col8, #T_16ba8_row10_col9, #T_16ba8_row10_col10, #T_16ba8_row10_col11, #T_16ba8_row10_col12, #T_16ba8_row10_col13, #T_16ba8_row10_col14, #T_16ba8_row10_col15, #T_16ba8_row10_col16, #T_16ba8_row10_col17, #T_16ba8_row10_col18, #T_16ba8_row10_col19, #T_16ba8_row10_col20, #T_16ba8_row10_col21, #T_16ba8_row10_col22, #T_16ba8_row10_col23, #T_16ba8_row10_col24, #T_16ba8_row10_col25, #T_16ba8_row10_col26, #T_16ba8_row10_col27, #T_16ba8_row10_col28, #T_16ba8_row10_col29, #T_16ba8_row10_col30, #T_16ba8_row10_col31, #T_16ba8_row10_col32, #T_16ba8_row10_col33, #T_16ba8_row11_col4, #T_16ba8_row11_col5, #T_16ba8_row11_col6, #T_16ba8_row11_col7, #T_16ba8_row11_col8, #T_16ba8_row11_col9, #T_16ba8_row11_col10, #T_16ba8_row11_col11, #T_16ba8_row11_col12, #T_16ba8_row11_col13, #T_16ba8_row11_col14, #T_16ba8_row11_col15, #T_16ba8_row11_col16, #T_16ba8_row11_col17, #T_16ba8_row11_col18, #T_16ba8_row11_col19, #T_16ba8_row11_col20, #T_16ba8_row11_col21, #T_16ba8_row11_col22, #T_16ba8_row11_col23, #T_16ba8_row11_col24, #T_16ba8_row11_col25, #T_16ba8_row11_col26, #T_16ba8_row11_col27, #T_16ba8_row11_col28, #T_16ba8_row11_col29, #T_16ba8_row11_col30, #T_16ba8_row11_col31, #T_16ba8_row11_col32, #T_16ba8_row11_col33, #T_16ba8_row12_col4, #T_16ba8_row12_col5, #T_16ba8_row12_col6, #T_16ba8_row12_col7, #T_16ba8_row12_col8, #T_16ba8_row12_col9, #T_16ba8_row12_col10, #T_16ba8_row12_col11, #T_16ba8_row12_col12, #T_16ba8_row12_col13, #T_16ba8_row12_col14, #T_16ba8_row12_col15, #T_16ba8_row12_col16, #T_16ba8_row12_col17, #T_16ba8_row12_col18, #T_16ba8_row12_col19, #T_16ba8_row12_col20, #T_16ba8_row12_col21, #T_16ba8_row12_col22, #T_16ba8_row12_col23, #T_16ba8_row12_col24, #T_16ba8_row12_col25, #T_16ba8_row12_col26, #T_16ba8_row12_col27, #T_16ba8_row12_col28, #T_16ba8_row12_col29, #T_16ba8_row12_col30, #T_16ba8_row12_col31, #T_16ba8_row12_col32, #T_16ba8_row12_col33, #T_16ba8_row13_col4, #T_16ba8_row13_col5, #T_16ba8_row13_col6, #T_16ba8_row13_col7, #T_16ba8_row13_col8, #T_16ba8_row13_col9, #T_16ba8_row13_col10, #T_16ba8_row13_col11, #T_16ba8_row13_col12, #T_16ba8_row13_col13, #T_16ba8_row13_col14, #T_16ba8_row13_col15, #T_16ba8_row13_col16, #T_16ba8_row13_col17, #T_16ba8_row13_col18, #T_16ba8_row13_col19, #T_16ba8_row13_col20, #T_16ba8_row13_col21, #T_16ba8_row13_col22, #T_16ba8_row13_col23, #T_16ba8_row13_col24, #T_16ba8_row13_col25, #T_16ba8_row13_col26, #T_16ba8_row13_col27, #T_16ba8_row13_col28, #T_16ba8_row13_col29, #T_16ba8_row13_col30, #T_16ba8_row13_col31, #T_16ba8_row13_col32, #T_16ba8_row13_col33 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_16ba8_row1_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row1_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 79.1%, transparent 79.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row1_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 80.4%, transparent 80.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row1_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 79.3%, transparent 79.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row2_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 77.6%, transparent 77.6%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row2_col1, #T_16ba8_row3_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 77.4%, transparent 77.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row2_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 78.7%, transparent 78.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row2_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 77.6%, transparent 77.6%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row3_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 77.5%, transparent 77.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row3_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 78.0%, transparent 78.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row3_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 77.5%, transparent 77.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row4_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 76.4%, transparent 76.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row4_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 76.2%, transparent 76.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row4_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 77.2%, transparent 77.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row4_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 76.4%, transparent 76.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row5_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row5_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 70.0%, transparent 70.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row5_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 71.8%, transparent 71.8%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row5_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row6_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 69.9%, transparent 69.9%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row6_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 69.7%, transparent 69.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row6_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.5%, transparent 70.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row6_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 69.9%, transparent 69.9%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row7_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 68.7%, transparent 68.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row7_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 68.2%, transparent 68.2%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row7_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.0%, transparent 70.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row7_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 68.7%, transparent 68.7%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row8_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 65.4%, transparent 65.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row8_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 63.1%, transparent 63.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row8_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 70.6%, transparent 70.6%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row8_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 65.5%, transparent 65.5%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row9_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 67.4%, transparent 67.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row9_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 67.3%, transparent 67.3%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row9_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 67.6%, transparent 67.6%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row9_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 67.4%, transparent 67.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row10_col0, #T_16ba8_row11_col0, #T_16ba8_row12_col0, #T_16ba8_row13_col0 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #f5f8d6 50.1%, transparent 50.1%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row10_col1, #T_16ba8_row11_col1, #T_16ba8_row12_col1, #T_16ba8_row13_col1 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #c778c8 33.4%, transparent 33.4%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row10_col2, #T_16ba8_row11_col2, #T_16ba8_row12_col2, #T_16ba8_row13_col2 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #ff4971 25.0%, transparent 25.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_16ba8_row10_col3, #T_16ba8_row11_col3, #T_16ba8_row12_col3, #T_16ba8_row13_col3 {\n",
       "  text-align: center;\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #aadbaa 50.0%, transparent 50.0%);\n",
       "  color: #251e1b;\n",
       "  font-size: 12px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_16ba8\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_16ba8_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_16ba8_level0_col1\" class=\"col_heading level0 col1\" >f1_score</th>\n",
       "      <th id=\"T_16ba8_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_16ba8_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_16ba8_level0_col4\" class=\"col_heading level0 col4\" >ml_framework</th>\n",
       "      <th id=\"T_16ba8_level0_col5\" class=\"col_heading level0 col5\" >transfer_learning</th>\n",
       "      <th id=\"T_16ba8_level0_col6\" class=\"col_heading level0 col6\" >deep_learning</th>\n",
       "      <th id=\"T_16ba8_level0_col7\" class=\"col_heading level0 col7\" >model_type</th>\n",
       "      <th id=\"T_16ba8_level0_col8\" class=\"col_heading level0 col8\" >depth</th>\n",
       "      <th id=\"T_16ba8_level0_col9\" class=\"col_heading level0 col9\" >num_params</th>\n",
       "      <th id=\"T_16ba8_level0_col10\" class=\"col_heading level0 col10\" >embedding_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col11\" class=\"col_heading level0 col11\" >conv1d_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col12\" class=\"col_heading level0 col12\" >maxpooling1d_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col13\" class=\"col_heading level0 col13\" >simplernn_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col14\" class=\"col_heading level0 col14\" >dropout_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col15\" class=\"col_heading level0 col15\" >flatten_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col16\" class=\"col_heading level0 col16\" >lstm_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col17\" class=\"col_heading level0 col17\" >inputlayer_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col18\" class=\"col_heading level0 col18\" >concatenate_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col19\" class=\"col_heading level0 col19\" >bidirectional_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col20\" class=\"col_heading level0 col20\" >globalmaxpooling1d_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col21\" class=\"col_heading level0 col21\" >globalaveragepooling1d_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col22\" class=\"col_heading level0 col22\" >dense_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col23\" class=\"col_heading level0 col23\" >batchnormalization_layers</th>\n",
       "      <th id=\"T_16ba8_level0_col24\" class=\"col_heading level0 col24\" >sigmoid_act</th>\n",
       "      <th id=\"T_16ba8_level0_col25\" class=\"col_heading level0 col25\" >softmax_act</th>\n",
       "      <th id=\"T_16ba8_level0_col26\" class=\"col_heading level0 col26\" >tanh_act</th>\n",
       "      <th id=\"T_16ba8_level0_col27\" class=\"col_heading level0 col27\" >relu_act</th>\n",
       "      <th id=\"T_16ba8_level0_col28\" class=\"col_heading level0 col28\" >loss</th>\n",
       "      <th id=\"T_16ba8_level0_col29\" class=\"col_heading level0 col29\" >optimizer</th>\n",
       "      <th id=\"T_16ba8_level0_col30\" class=\"col_heading level0 col30\" >memory_size</th>\n",
       "      <th id=\"T_16ba8_level0_col31\" class=\"col_heading level0 col31\" >team</th>\n",
       "      <th id=\"T_16ba8_level0_col32\" class=\"col_heading level0 col32\" >username</th>\n",
       "      <th id=\"T_16ba8_level0_col33\" class=\"col_heading level0 col33\" >version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row0\" class=\"row_heading level0 row0\" >46</th>\n",
       "      <td id=\"T_16ba8_row0_col0\" class=\"data row0 col0\" >79.36%</td>\n",
       "      <td id=\"T_16ba8_row0_col1\" class=\"data row0 col1\" >79.25%</td>\n",
       "      <td id=\"T_16ba8_row0_col2\" class=\"data row0 col2\" >80.03%</td>\n",
       "      <td id=\"T_16ba8_row0_col3\" class=\"data row0 col3\" >79.37%</td>\n",
       "      <td id=\"T_16ba8_row0_col4\" class=\"data row0 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col6\" class=\"data row0 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row0_col7\" class=\"data row0 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row0_col8\" class=\"data row0 col8\" >5.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col9\" class=\"data row0 col9\" >174658.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col10\" class=\"data row0 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col15\" class=\"data row0 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col16\" class=\"data row0 col16\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col18\" class=\"data row0 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col20\" class=\"data row0 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col21\" class=\"data row0 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col22\" class=\"data row0 col22\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col23\" class=\"data row0 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col24\" class=\"data row0 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col25\" class=\"data row0 col25\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col26\" class=\"data row0 col26\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col27\" class=\"data row0 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row0_col28\" class=\"data row0 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row0_col29\" class=\"data row0 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row0_col30\" class=\"data row0 col30\" >699936.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col31\" class=\"data row0 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row0_col32\" class=\"data row0 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row0_col33\" class=\"data row0 col33\" >252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row1\" class=\"row_heading level0 row1\" >47</th>\n",
       "      <td id=\"T_16ba8_row1_col0\" class=\"data row1 col0\" >79.25%</td>\n",
       "      <td id=\"T_16ba8_row1_col1\" class=\"data row1 col1\" >79.06%</td>\n",
       "      <td id=\"T_16ba8_row1_col2\" class=\"data row1 col2\" >80.41%</td>\n",
       "      <td id=\"T_16ba8_row1_col3\" class=\"data row1 col3\" >79.26%</td>\n",
       "      <td id=\"T_16ba8_row1_col4\" class=\"data row1 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col6\" class=\"data row1 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row1_col7\" class=\"data row1 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row1_col8\" class=\"data row1 col8\" >5.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col9\" class=\"data row1 col9\" >174658.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col10\" class=\"data row1 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col15\" class=\"data row1 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col16\" class=\"data row1 col16\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col18\" class=\"data row1 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col19\" class=\"data row1 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col20\" class=\"data row1 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col21\" class=\"data row1 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col22\" class=\"data row1 col22\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col23\" class=\"data row1 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col24\" class=\"data row1 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col25\" class=\"data row1 col25\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col26\" class=\"data row1 col26\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col27\" class=\"data row1 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row1_col28\" class=\"data row1 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row1_col29\" class=\"data row1 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row1_col30\" class=\"data row1 col30\" >699936.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col31\" class=\"data row1 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row1_col32\" class=\"data row1 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row1_col33\" class=\"data row1 col33\" >55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row2\" class=\"row_heading level0 row2\" >89</th>\n",
       "      <td id=\"T_16ba8_row2_col0\" class=\"data row2 col0\" >77.61%</td>\n",
       "      <td id=\"T_16ba8_row2_col1\" class=\"data row2 col1\" >77.39%</td>\n",
       "      <td id=\"T_16ba8_row2_col2\" class=\"data row2 col2\" >78.73%</td>\n",
       "      <td id=\"T_16ba8_row2_col3\" class=\"data row2 col3\" >77.62%</td>\n",
       "      <td id=\"T_16ba8_row2_col4\" class=\"data row2 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col6\" class=\"data row2 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row2_col7\" class=\"data row2 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row2_col8\" class=\"data row2 col8\" >5.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col9\" class=\"data row2 col9\" >174658.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col10\" class=\"data row2 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col15\" class=\"data row2 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col16\" class=\"data row2 col16\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col18\" class=\"data row2 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col19\" class=\"data row2 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col20\" class=\"data row2 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col21\" class=\"data row2 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col22\" class=\"data row2 col22\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col23\" class=\"data row2 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col24\" class=\"data row2 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col25\" class=\"data row2 col25\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col26\" class=\"data row2 col26\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col27\" class=\"data row2 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row2_col28\" class=\"data row2 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row2_col29\" class=\"data row2 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row2_col30\" class=\"data row2 col30\" >699936.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col31\" class=\"data row2 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row2_col32\" class=\"data row2 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row2_col33\" class=\"data row2 col33\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row3\" class=\"row_heading level0 row3\" >101</th>\n",
       "      <td id=\"T_16ba8_row3_col0\" class=\"data row3 col0\" >77.50%</td>\n",
       "      <td id=\"T_16ba8_row3_col1\" class=\"data row3 col1\" >77.41%</td>\n",
       "      <td id=\"T_16ba8_row3_col2\" class=\"data row3 col2\" >77.97%</td>\n",
       "      <td id=\"T_16ba8_row3_col3\" class=\"data row3 col3\" >77.50%</td>\n",
       "      <td id=\"T_16ba8_row3_col4\" class=\"data row3 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col6\" class=\"data row3 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row3_col7\" class=\"data row3 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row3_col8\" class=\"data row3 col8\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col9\" class=\"data row3 col9\" >161282.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col10\" class=\"data row3 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col15\" class=\"data row3 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col16\" class=\"data row3 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col18\" class=\"data row3 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col19\" class=\"data row3 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col20\" class=\"data row3 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col21\" class=\"data row3 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col22\" class=\"data row3 col22\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col23\" class=\"data row3 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col24\" class=\"data row3 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col25\" class=\"data row3 col25\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col26\" class=\"data row3 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col27\" class=\"data row3 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col28\" class=\"data row3 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row3_col29\" class=\"data row3 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row3_col30\" class=\"data row3 col30\" >645600.000000</td>\n",
       "      <td id=\"T_16ba8_row3_col31\" class=\"data row3 col31\" >nan</td>\n",
       "      <td id=\"T_16ba8_row3_col32\" class=\"data row3 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row3_col33\" class=\"data row3 col33\" >44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row4\" class=\"row_heading level0 row4\" >119</th>\n",
       "      <td id=\"T_16ba8_row4_col0\" class=\"data row4 col0\" >76.40%</td>\n",
       "      <td id=\"T_16ba8_row4_col1\" class=\"data row4 col1\" >76.23%</td>\n",
       "      <td id=\"T_16ba8_row4_col2\" class=\"data row4 col2\" >77.18%</td>\n",
       "      <td id=\"T_16ba8_row4_col3\" class=\"data row4 col3\" >76.41%</td>\n",
       "      <td id=\"T_16ba8_row4_col4\" class=\"data row4 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col6\" class=\"data row4 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row4_col7\" class=\"data row4 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row4_col8\" class=\"data row4 col8\" >5.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col9\" class=\"data row4 col9\" >161294.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col10\" class=\"data row4 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col15\" class=\"data row4 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col16\" class=\"data row4 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col18\" class=\"data row4 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col19\" class=\"data row4 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col20\" class=\"data row4 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col21\" class=\"data row4 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col22\" class=\"data row4 col22\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col23\" class=\"data row4 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col24\" class=\"data row4 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col25\" class=\"data row4 col25\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col26\" class=\"data row4 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col27\" class=\"data row4 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col28\" class=\"data row4 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row4_col29\" class=\"data row4 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row4_col30\" class=\"data row4 col30\" >646160.000000</td>\n",
       "      <td id=\"T_16ba8_row4_col31\" class=\"data row4 col31\" >nan</td>\n",
       "      <td id=\"T_16ba8_row4_col32\" class=\"data row4 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row4_col33\" class=\"data row4 col33\" >47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row5\" class=\"row_heading level0 row5\" >162</th>\n",
       "      <td id=\"T_16ba8_row5_col0\" class=\"data row5 col0\" >70.47%</td>\n",
       "      <td id=\"T_16ba8_row5_col1\" class=\"data row5 col1\" >70.02%</td>\n",
       "      <td id=\"T_16ba8_row5_col2\" class=\"data row5 col2\" >71.82%</td>\n",
       "      <td id=\"T_16ba8_row5_col3\" class=\"data row5 col3\" >70.49%</td>\n",
       "      <td id=\"T_16ba8_row5_col4\" class=\"data row5 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col6\" class=\"data row5 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row5_col7\" class=\"data row5 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row5_col8\" class=\"data row5 col8\" >10.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col9\" class=\"data row5 col9\" >162170.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col10\" class=\"data row5 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col11\" class=\"data row5 col11\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col12\" class=\"data row5 col12\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col15\" class=\"data row5 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col16\" class=\"data row5 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col18\" class=\"data row5 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col19\" class=\"data row5 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col20\" class=\"data row5 col20\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col21\" class=\"data row5 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col22\" class=\"data row5 col22\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col23\" class=\"data row5 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col24\" class=\"data row5 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col25\" class=\"data row5 col25\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col26\" class=\"data row5 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row5_col27\" class=\"data row5 col27\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col28\" class=\"data row5 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row5_col29\" class=\"data row5 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row5_col30\" class=\"data row5 col30\" >650480.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col31\" class=\"data row5 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row5_col32\" class=\"data row5 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row5_col33\" class=\"data row5 col33\" >56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row6\" class=\"row_heading level0 row6\" >168</th>\n",
       "      <td id=\"T_16ba8_row6_col0\" class=\"data row6 col0\" >69.92%</td>\n",
       "      <td id=\"T_16ba8_row6_col1\" class=\"data row6 col1\" >69.73%</td>\n",
       "      <td id=\"T_16ba8_row6_col2\" class=\"data row6 col2\" >70.46%</td>\n",
       "      <td id=\"T_16ba8_row6_col3\" class=\"data row6 col3\" >69.93%</td>\n",
       "      <td id=\"T_16ba8_row6_col4\" class=\"data row6 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row6_col5\" class=\"data row6 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col6\" class=\"data row6 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row6_col7\" class=\"data row6 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row6_col8\" class=\"data row6 col8\" >10.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col9\" class=\"data row6 col9\" >162170.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col10\" class=\"data row6 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col11\" class=\"data row6 col11\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col12\" class=\"data row6 col12\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col15\" class=\"data row6 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col16\" class=\"data row6 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col18\" class=\"data row6 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col19\" class=\"data row6 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col20\" class=\"data row6 col20\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col21\" class=\"data row6 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col22\" class=\"data row6 col22\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col23\" class=\"data row6 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col24\" class=\"data row6 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col25\" class=\"data row6 col25\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col26\" class=\"data row6 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row6_col27\" class=\"data row6 col27\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col28\" class=\"data row6 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row6_col29\" class=\"data row6 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row6_col30\" class=\"data row6 col30\" >650480.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col31\" class=\"data row6 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row6_col32\" class=\"data row6 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row6_col33\" class=\"data row6 col33\" >253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row7\" class=\"row_heading level0 row7\" >178</th>\n",
       "      <td id=\"T_16ba8_row7_col0\" class=\"data row7 col0\" >68.72%</td>\n",
       "      <td id=\"T_16ba8_row7_col1\" class=\"data row7 col1\" >68.20%</td>\n",
       "      <td id=\"T_16ba8_row7_col2\" class=\"data row7 col2\" >70.04%</td>\n",
       "      <td id=\"T_16ba8_row7_col3\" class=\"data row7 col3\" >68.73%</td>\n",
       "      <td id=\"T_16ba8_row7_col4\" class=\"data row7 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row7_col5\" class=\"data row7 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col6\" class=\"data row7 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row7_col7\" class=\"data row7 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row7_col8\" class=\"data row7 col8\" >10.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col9\" class=\"data row7 col9\" >162170.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col10\" class=\"data row7 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col11\" class=\"data row7 col11\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col12\" class=\"data row7 col12\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col15\" class=\"data row7 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col16\" class=\"data row7 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col18\" class=\"data row7 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col19\" class=\"data row7 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col20\" class=\"data row7 col20\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col21\" class=\"data row7 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col22\" class=\"data row7 col22\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col23\" class=\"data row7 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col24\" class=\"data row7 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col25\" class=\"data row7 col25\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col26\" class=\"data row7 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row7_col27\" class=\"data row7 col27\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col28\" class=\"data row7 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row7_col29\" class=\"data row7 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row7_col30\" class=\"data row7 col30\" >650480.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col31\" class=\"data row7 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row7_col32\" class=\"data row7 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row7_col33\" class=\"data row7 col33\" >53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row8\" class=\"row_heading level0 row8\" >185</th>\n",
       "      <td id=\"T_16ba8_row8_col0\" class=\"data row8 col0\" >65.42%</td>\n",
       "      <td id=\"T_16ba8_row8_col1\" class=\"data row8 col1\" >63.11%</td>\n",
       "      <td id=\"T_16ba8_row8_col2\" class=\"data row8 col2\" >70.65%</td>\n",
       "      <td id=\"T_16ba8_row8_col3\" class=\"data row8 col3\" >65.45%</td>\n",
       "      <td id=\"T_16ba8_row8_col4\" class=\"data row8 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row8_col5\" class=\"data row8 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col6\" class=\"data row8 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row8_col7\" class=\"data row8 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row8_col8\" class=\"data row8 col8\" >5.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col9\" class=\"data row8 col9\" >174658.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col10\" class=\"data row8 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col12\" class=\"data row8 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col14\" class=\"data row8 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col15\" class=\"data row8 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col16\" class=\"data row8 col16\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col17\" class=\"data row8 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col18\" class=\"data row8 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col19\" class=\"data row8 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col20\" class=\"data row8 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col21\" class=\"data row8 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col22\" class=\"data row8 col22\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col23\" class=\"data row8 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col24\" class=\"data row8 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col25\" class=\"data row8 col25\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col26\" class=\"data row8 col26\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col27\" class=\"data row8 col27\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col28\" class=\"data row8 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row8_col29\" class=\"data row8 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row8_col30\" class=\"data row8 col30\" >699936.000000</td>\n",
       "      <td id=\"T_16ba8_row8_col31\" class=\"data row8 col31\" >nan</td>\n",
       "      <td id=\"T_16ba8_row8_col32\" class=\"data row8 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row8_col33\" class=\"data row8 col33\" >52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row9\" class=\"row_heading level0 row9\" >187</th>\n",
       "      <td id=\"T_16ba8_row9_col0\" class=\"data row9 col0\" >67.40%</td>\n",
       "      <td id=\"T_16ba8_row9_col1\" class=\"data row9 col1\" >67.32%</td>\n",
       "      <td id=\"T_16ba8_row9_col2\" class=\"data row9 col2\" >67.59%</td>\n",
       "      <td id=\"T_16ba8_row9_col3\" class=\"data row9 col3\" >67.40%</td>\n",
       "      <td id=\"T_16ba8_row9_col4\" class=\"data row9 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row9_col5\" class=\"data row9 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col6\" class=\"data row9 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row9_col7\" class=\"data row9 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row9_col8\" class=\"data row9 col8\" >10.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col9\" class=\"data row9 col9\" >162170.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col10\" class=\"data row9 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col11\" class=\"data row9 col11\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col12\" class=\"data row9 col12\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col13\" class=\"data row9 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col14\" class=\"data row9 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col15\" class=\"data row9 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col16\" class=\"data row9 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col17\" class=\"data row9 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col18\" class=\"data row9 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col19\" class=\"data row9 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col20\" class=\"data row9 col20\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col21\" class=\"data row9 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col22\" class=\"data row9 col22\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col23\" class=\"data row9 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col24\" class=\"data row9 col24\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col25\" class=\"data row9 col25\" >3.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col26\" class=\"data row9 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row9_col27\" class=\"data row9 col27\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col28\" class=\"data row9 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row9_col29\" class=\"data row9 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row9_col30\" class=\"data row9 col30\" >650480.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col31\" class=\"data row9 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row9_col32\" class=\"data row9 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row9_col33\" class=\"data row9 col33\" >258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row10\" class=\"row_heading level0 row10\" >229</th>\n",
       "      <td id=\"T_16ba8_row10_col0\" class=\"data row10 col0\" >50.05%</td>\n",
       "      <td id=\"T_16ba8_row10_col1\" class=\"data row10 col1\" >33.36%</td>\n",
       "      <td id=\"T_16ba8_row10_col2\" class=\"data row10 col2\" >25.03%</td>\n",
       "      <td id=\"T_16ba8_row10_col3\" class=\"data row10 col3\" >50.00%</td>\n",
       "      <td id=\"T_16ba8_row10_col4\" class=\"data row10 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row10_col5\" class=\"data row10 col5\" >True</td>\n",
       "      <td id=\"T_16ba8_row10_col6\" class=\"data row10 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row10_col7\" class=\"data row10 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row10_col8\" class=\"data row10 col8\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col9\" class=\"data row10 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col11\" class=\"data row10 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col12\" class=\"data row10 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col13\" class=\"data row10 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col14\" class=\"data row10 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col15\" class=\"data row10 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col16\" class=\"data row10 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col17\" class=\"data row10 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col18\" class=\"data row10 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col19\" class=\"data row10 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col20\" class=\"data row10 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col21\" class=\"data row10 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col22\" class=\"data row10 col22\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col23\" class=\"data row10 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col24\" class=\"data row10 col24\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col25\" class=\"data row10 col25\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col26\" class=\"data row10 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row10_col27\" class=\"data row10 col27\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col28\" class=\"data row10 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row10_col29\" class=\"data row10 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row10_col30\" class=\"data row10 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col31\" class=\"data row10 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row10_col32\" class=\"data row10 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row10_col33\" class=\"data row10 col33\" >255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row11\" class=\"row_heading level0 row11\" >230</th>\n",
       "      <td id=\"T_16ba8_row11_col0\" class=\"data row11 col0\" >50.05%</td>\n",
       "      <td id=\"T_16ba8_row11_col1\" class=\"data row11 col1\" >33.36%</td>\n",
       "      <td id=\"T_16ba8_row11_col2\" class=\"data row11 col2\" >25.03%</td>\n",
       "      <td id=\"T_16ba8_row11_col3\" class=\"data row11 col3\" >50.00%</td>\n",
       "      <td id=\"T_16ba8_row11_col4\" class=\"data row11 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row11_col5\" class=\"data row11 col5\" >True</td>\n",
       "      <td id=\"T_16ba8_row11_col6\" class=\"data row11 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row11_col7\" class=\"data row11 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row11_col8\" class=\"data row11 col8\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col9\" class=\"data row11 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col10\" class=\"data row11 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col11\" class=\"data row11 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col12\" class=\"data row11 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col13\" class=\"data row11 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col14\" class=\"data row11 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col15\" class=\"data row11 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col16\" class=\"data row11 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col17\" class=\"data row11 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col18\" class=\"data row11 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col19\" class=\"data row11 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col20\" class=\"data row11 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col21\" class=\"data row11 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col22\" class=\"data row11 col22\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col23\" class=\"data row11 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col24\" class=\"data row11 col24\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col25\" class=\"data row11 col25\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col26\" class=\"data row11 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row11_col27\" class=\"data row11 col27\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col28\" class=\"data row11 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row11_col29\" class=\"data row11 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row11_col30\" class=\"data row11 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col31\" class=\"data row11 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row11_col32\" class=\"data row11 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row11_col33\" class=\"data row11 col33\" >259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row12\" class=\"row_heading level0 row12\" >232</th>\n",
       "      <td id=\"T_16ba8_row12_col0\" class=\"data row12 col0\" >50.05%</td>\n",
       "      <td id=\"T_16ba8_row12_col1\" class=\"data row12 col1\" >33.36%</td>\n",
       "      <td id=\"T_16ba8_row12_col2\" class=\"data row12 col2\" >25.03%</td>\n",
       "      <td id=\"T_16ba8_row12_col3\" class=\"data row12 col3\" >50.00%</td>\n",
       "      <td id=\"T_16ba8_row12_col4\" class=\"data row12 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row12_col5\" class=\"data row12 col5\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col6\" class=\"data row12 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row12_col7\" class=\"data row12 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row12_col8\" class=\"data row12 col8\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col9\" class=\"data row12 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col10\" class=\"data row12 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col11\" class=\"data row12 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col12\" class=\"data row12 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col13\" class=\"data row12 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col14\" class=\"data row12 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col15\" class=\"data row12 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col16\" class=\"data row12 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col17\" class=\"data row12 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col18\" class=\"data row12 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col19\" class=\"data row12 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col20\" class=\"data row12 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col21\" class=\"data row12 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col22\" class=\"data row12 col22\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col23\" class=\"data row12 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col24\" class=\"data row12 col24\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col25\" class=\"data row12 col25\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col26\" class=\"data row12 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row12_col27\" class=\"data row12 col27\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col28\" class=\"data row12 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row12_col29\" class=\"data row12 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row12_col30\" class=\"data row12 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col31\" class=\"data row12 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row12_col32\" class=\"data row12 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row12_col33\" class=\"data row12 col33\" >54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_16ba8_level0_row13\" class=\"row_heading level0 row13\" >233</th>\n",
       "      <td id=\"T_16ba8_row13_col0\" class=\"data row13 col0\" >50.05%</td>\n",
       "      <td id=\"T_16ba8_row13_col1\" class=\"data row13 col1\" >33.36%</td>\n",
       "      <td id=\"T_16ba8_row13_col2\" class=\"data row13 col2\" >25.03%</td>\n",
       "      <td id=\"T_16ba8_row13_col3\" class=\"data row13 col3\" >50.00%</td>\n",
       "      <td id=\"T_16ba8_row13_col4\" class=\"data row13 col4\" >keras</td>\n",
       "      <td id=\"T_16ba8_row13_col5\" class=\"data row13 col5\" >True</td>\n",
       "      <td id=\"T_16ba8_row13_col6\" class=\"data row13 col6\" >True</td>\n",
       "      <td id=\"T_16ba8_row13_col7\" class=\"data row13 col7\" >Sequential</td>\n",
       "      <td id=\"T_16ba8_row13_col8\" class=\"data row13 col8\" >4.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col9\" class=\"data row13 col9\" >1320065.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col10\" class=\"data row13 col10\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col11\" class=\"data row13 col11\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col12\" class=\"data row13 col12\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col13\" class=\"data row13 col13\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col14\" class=\"data row13 col14\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col15\" class=\"data row13 col15\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col16\" class=\"data row13 col16\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col17\" class=\"data row13 col17\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col18\" class=\"data row13 col18\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col19\" class=\"data row13 col19\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col20\" class=\"data row13 col20\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col21\" class=\"data row13 col21\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col22\" class=\"data row13 col22\" >2.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col23\" class=\"data row13 col23\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col24\" class=\"data row13 col24\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col25\" class=\"data row13 col25\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col26\" class=\"data row13 col26\" >nan</td>\n",
       "      <td id=\"T_16ba8_row13_col27\" class=\"data row13 col27\" >1.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col28\" class=\"data row13 col28\" >str</td>\n",
       "      <td id=\"T_16ba8_row13_col29\" class=\"data row13 col29\" >RMSprop</td>\n",
       "      <td id=\"T_16ba8_row13_col30\" class=\"data row13 col30\" >5281008.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col31\" class=\"data row13 col31\" >7.000000</td>\n",
       "      <td id=\"T_16ba8_row13_col32\" class=\"data row13 col32\" >lprockop</td>\n",
       "      <td id=\"T_16ba8_row13_col33\" class=\"data row13 col33\" >57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f643fe8f610>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get leaderboard to explore current best model architectures\n",
    "\n",
    "# Get raw data in pandas data frame\n",
    "data = mycompetition.get_leaderboard()\n",
    "\n",
    "my_data = data[data['username'] == 'lprockop']\n",
    "\n",
    "# Stylize leaderboard data\n",
    "mycompetition.stylize_leaderboard(my_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
